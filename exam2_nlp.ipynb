{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exam2_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varchala/NaturalLanguageProcessing_CSC8980/blob/main/exam2_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guasZh2J8Vc8"
      },
      "source": [
        "# **G Varchaleswari**\n",
        "\n",
        "vganugapati1@student.gsu.edu "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BShziUX-dj1M",
        "outputId": "9351c76d-fb0f-4b3e-fbfe-f910db37ae29"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "from nltk.corpus import abc\n",
        "from collections import Counter, defaultdict\n",
        "import nltk, re\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk import bigrams, trigrams\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwTH4TA_eK8r"
      },
      "source": [
        "seed_value = 12345"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5YFczAZfPSX"
      },
      "source": [
        "#**Question 1) (20 points)**\n",
        "Write a function that takes a List of five words: [‘apple’, ‘house’, ‘pear’,\n",
        "‘dog’, ‘doctor’] and returns a list of lists with each element being a word and a list of the top five\n",
        "most similar words. For this task you have to use the most suitable method of the ones we have\n",
        "seen in class to determine the most similar words to the original input list. You can use a\n",
        "pre-trained resource if you think is appropriate. After calling your function, print the most similar\n",
        "words to the screen. Are these ‘similar’ words actually similar? If not, why not? What do you\n",
        "think can be improved and how - talk about it, do not necessarily implement it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ObQ9jGff0QJ",
        "outputId": "bfe379f2-5ce2-41f9-f2f5-026e6a81607d"
      },
      "source": [
        "!gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Permission denied: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "Maybe you need to change permission over 'Anyone with the link'?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3k6s-DAim0B",
        "outputId": "1d00fd27-c8d8-4a4f-e230-c95a15724d44"
      },
      "source": [
        "!gunzip /content/drive/MyDrive/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVgfrmFDjrN0"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Sw4XO-rqyM"
      },
      "source": [
        "filename = '/content/drive/MyDrive/GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgSlKyw9yZ7M",
        "outputId": "5839c27f-d8c0-43e9-d526-364acb2c7542"
      },
      "source": [
        "for i in model.most_similar('apple')[0:6]:\n",
        "  print(i[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apples\n",
            "pear\n",
            "fruit\n",
            "berry\n",
            "pears\n",
            "strawberry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFatkNGfQBMC",
        "outputId": "6ee62f43-4057-4358-989a-4dc789d9deec"
      },
      "source": [
        "for i in model.most_similar('dog')[0:10]:\n",
        "  print(i[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dogs\n",
            "puppy\n",
            "pit_bull\n",
            "pooch\n",
            "cat\n",
            "golden_retriever\n",
            "German_shepherd\n",
            "Rottweiler\n",
            "beagle\n",
            "pup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dzS47g0fAu3"
      },
      "source": [
        "def word_similarity(words):\n",
        "  word_vec_list = []\n",
        "  for i in words:\n",
        "    docs = []\n",
        "    for j in model.most_similar(i)[0:5]:\n",
        "      docs.append(j[0])\n",
        "    word_vec_list.append(docs)\n",
        "  return word_vec_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3NiraBwqu51"
      },
      "source": [
        "sim_Call= word_similarity( ['apple', 'house', 'pear','dog', 'doctor'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voMwwD2wsmXr",
        "outputId": "0c6531bb-8195-4ccd-dad1-c8544506212f"
      },
      "source": [
        "sim_Call"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['apples', 'pear', 'fruit', 'berry', 'pears'],\n",
              " ['houses', 'bungalow', 'apartment', 'bedroom', 'townhouse'],\n",
              " ['pears', 'apricot', 'apricots', 'nectarine', 'Fuji_apple'],\n",
              " ['dogs', 'puppy', 'pit_bull', 'pooch', 'cat'],\n",
              " ['physician', 'doctors', 'gynecologist', 'surgeon', 'dentist']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe7VBYgWIjVg"
      },
      "source": [
        "Few words that were obtained in the list are quite similar although a few words are redundant. This is one problem I noticed which could be curbed by applying nlp techniques like lemmatization and stemming. A word like 'cat' in comparision to dog is not apt given that the similar words are a set of dog breeds. This is also because cat is an animal the model is categorizing it in the similar way. This could be improved by training the model with a dataset that is relevant to context,i.e. a dataset that has enough combination of sentences to lay a proper distinction between a cat and a dog. But to practically do this at a word level becomes nearly impossible. However, the kind of dataset used to train the neural network, as in word2vec, makes a huge difference and so a relevant dataset could solve this kind of problems to some extent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsGYlQIKgcJs"
      },
      "source": [
        "# **Question 2) (30 points)**\n",
        "\n",
        "Using the Homework 2 dataset, also attached in the Exam 2 files, shakespeares-works_TXT_FolgerShakespeare.zip. Find the document to document similarity using:\n",
        "\n",
        "a) Cosine similarity. And create a 42 x 42 heatmap of these similarities.\n",
        "\n",
        "b) Use Doc2Vec to create document embeddings and find the similarities between the documents. To visualize this, also create a 42 x 42 heatmap for this.\n",
        "\n",
        "c) What are the differences you find between the two methods? Is there anything radically\n",
        "different? Please describe your answer in terms of the heatmap of part a and part b.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyD1gJCIguf9",
        "outputId": "b337d33d-0568-4356-bd1a-22188d52c5f7"
      },
      "source": [
        "path ='/content/drive/MyDrive/exam2/shakespeares-works_TXT_FolgerShakespeare'\n",
        "count=0\n",
        "fileMatrix=[]\n",
        "fileName=[]\n",
        "with os.scandir(path) as files:\n",
        "    for file in files:\n",
        "        if file.name.endswith(\".txt\"):\n",
        "            count +=1\n",
        "            fileName.append(file.name)\n",
        "            with open(path+\"/\"+file.name) as openfile:\n",
        "              fileMatrix.append(openfile.read())\n",
        "    print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUG5adjWi3hG",
        "outputId": "472351e4-e708-47fe-df27-ed8010740282"
      },
      "source": [
        "#TfidfVectorizer object\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# matrix of word vectors\n",
        "tfidf_matrix = vectorizer.fit_transform(fileMatrix)\n",
        "\n",
        "#shape of tfidf_matrix\n",
        "print(tfidf_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42, 24618)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rPFMoi2jHI4"
      },
      "source": [
        "# compute and print the cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "aHzoSnJijPYM",
        "outputId": "091d04d0-b6c3-469d-a866-e74cef629aef"
      },
      "source": [
        "import seaborn as sns; sns.set_theme()\n",
        "plt.figure(figsize=(9, 7))\n",
        "ax = sns.heatmap(cosine_sim, vmin=0, vmax=1,center=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51qVqi9olfLk"
      },
      "source": [
        "# **b)**\n",
        "Use Doc2Vec to create document embeddings and find the similarities between the\n",
        "documents. To visualize this, also create a 42 x 42 heatmap for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gwvTLWlmAh7",
        "outputId": "9ce719c1-c8ff-40c1-c29f-9d35560336a9"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAxUvk49lj33"
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnX8ON2qnPCS"
      },
      "source": [
        "# fileMatrix[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVa5dFwTpPhV",
        "outputId": "ab68105e-39ea-4557-8bd8-8e036f59a12c"
      },
      "source": [
        "print(fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['richard-iii_TXT_FolgerShakespeare.txt', 'much-ado-about-nothing_TXT_FolgerShakespeare.txt', 'henry-vi-part-3_TXT_FolgerShakespeare.txt', 'venus-and-adonis_TXT_FolgerShakespeare.txt', 'richard-ii_TXT_FolgerShakespeare.txt', 'the-winters-tale_TXT_FolgerShakespeare.txt', 'timon-of-athens_TXT_FolgerShakespeare.txt', 'the-merchant-of-venice_TXT_FolgerShakespeare.txt', 'troilus-and-cressida_TXT_FolgerShakespeare.txt', 'the-two-noble-kinsmen_TXT_FolgerShakespeare.txt', 'loves-labors-lost_TXT_FolgerShakespeare.txt', 'the-taming-of-the-shrew_TXT_FolgerShakespeare.txt', 'cymbeline_TXT_FolgerShakespeare.txt', 'coriolanus_TXT_FolgerShakespeare.txt', 'henry-viii_TXT_FolgerShakespeare.txt', 'the-tempest_TXT_FolgerShakespeare.txt', 'shakespeares-sonnets_TXT_FolgerShakespeare.txt', 'measure-for-measure_TXT_FolgerShakespeare.txt', 'alls-well-that-ends-well_TXT_FolgerShakespeare.txt', 'a-midsummer-nights-dream_TXT_FolgerShakespeare.txt', 'henry-iv-part-1_TXT_FolgerShakespeare.txt', 'henry-vi-part-1_TXT_FolgerShakespeare.txt', 'henry-v_TXT_FolgerShakespeare.txt', 'lucrece_TXT_FolgerShakespeare.txt', 'king-lear_TXT_FolgerShakespeare.txt', 'julius-caesar_TXT_FolgerShakespeare.txt', 'twelfth-night_TXT_FolgerShakespeare.txt', 'henry-vi-part-2_TXT_FolgerShakespeare.txt', 'antony-and-cleopatra_TXT_FolgerShakespeare.txt', 'the-merry-wives-of-windsor_TXT_FolgerShakespeare.txt', 'king-john_TXT_FolgerShakespeare.txt', 'henry-iv-part-2_TXT_FolgerShakespeare.txt', 'titus-andronicus_TXT_FolgerShakespeare.txt', 'pericles_TXT_FolgerShakespeare.txt', 'the-two-gentlemen-of-verona_TXT_FolgerShakespeare.txt', 'the-phoenix-and-turtle_TXT_FolgerShakespeare.txt', 'romeo-and-juliet_TXT_FolgerShakespeare.txt', 'othello_TXT_FolgerShakespeare.txt', 'as-you-like-it_TXT_FolgerShakespeare.txt', 'macbeth_TXT_FolgerShakespeare.txt', 'hamlet_TXT_FolgerShakespeare.txt', 'the-comedy-of-errors_TXT_FolgerShakespeare.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvdGEk97m7ja"
      },
      "source": [
        "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in zip(fileName,fileMatrix)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCdWPftTnvjq"
      },
      "source": [
        "model_doc2vec = Doc2Vec()\n",
        "model_doc2vec.build_vocab(tagged_data)\n",
        "model_doc2vec.train(tagged_data,total_examples=model_doc2vec.corpus_count,epochs=model_doc2vec.epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNKSStyIopgV",
        "outputId": "2a8c9e14-85b2-4d9f-abf2-8eb86181ef5f"
      },
      "source": [
        "# print(model_doc2vec.docvecs['richard-iii_TXT_FolgerShakespeare.txt'])\n",
        "docvec = []\n",
        "for i in fileName:\n",
        "  docvec.append(model_doc2vec.docvecs[i])\n",
        "print(len(docvec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVRiiK2Kp7U9"
      },
      "source": [
        "# compute and print the cosine similarity matrix\n",
        "cosine_sim_doc2vec = cosine_similarity(docvec, docvec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Ti3YjJt1qC8c",
        "outputId": "9b5592ec-93f3-4031-e22d-904c303e5ae5"
      },
      "source": [
        "plt.figure(figsize=(9, 7))\n",
        "ax = sns.heatmap(cosine_sim_doc2vec, vmin=0, vmax=1,center=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoLD5Z_2sLNM"
      },
      "source": [
        "# **c**\n",
        "What are the differences you find between the two methods? Is there anything radically different? Please describe your answer in terms of the heatmap of part a and part b."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYxfV3RhsOXT"
      },
      "source": [
        "The most important and clear difference that I find in the heatmap is that the **Model b** has greater similarity values between different documents as compared to **Model a**. This could be attributed to the method of computation used in these models for finding the document vectors. Model a uses TF-IDF in which words are given weights by term frequency and inverse document frequency instead of only the word frequencies in the document.This helps is finding the important words i.e. words that occur frequently will have less importance due to inverse frequency as compared to rare words. In doc2vec the models are built with underlying representations for each document and its words by using a neural network like CBOW and skipgrams as used in word2vec.Doc2Vec which is a generalization of word2vec model, uses words appearing around the particular word to find the vector (something like bigram and trigram models) whereas tf-idf uses the word frequency in the entire document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtpjATblyW48"
      },
      "source": [
        "#**Question 3)**\n",
        "\n",
        "(30 points) Using the Homework 2 dataset. Use SpaCy to extract the following:\n",
        "\n",
        "a) Write a function to generate all unique bigrams from all documents in the dataset. The\n",
        "input of this function should be the concatenated dataset and the output should be the\n",
        "list of bigrams and their frequency. Display the top 10 most common bigrams and their\n",
        "frequency.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRM-JuGm2rab"
      },
      "source": [
        "from nltk import bigrams, trigrams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsQ00cnc3lVp"
      },
      "source": [
        "# fileMatrix[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afmNuXZQ3yRY"
      },
      "source": [
        "fileMatrix_str = lambda a: \"\".join([i for i in a])\n",
        "docm_str = fileMatrix_str(fileMatrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6LNx1tN74sEX",
        "outputId": "4c80ee51-04ea-4d2f-c177-eb86cf66bdee"
      },
      "source": [
        "docm_str[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Richard II'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SiGXhuyy-_r"
      },
      "source": [
        "def generate_bigrams(sentences):\n",
        "  corpus=[]\n",
        "  for sentence in nltk.sent_tokenize(sentences):\n",
        "    corpus.append(nltk.word_tokenize(sentence))\n",
        "  model_bi = defaultdict(lambda: defaultdict(lambda: 0)) \n",
        "  for sentence in corpus:\n",
        "      for w1, w2 in bigrams(sentence):\n",
        "          # print(w1)\n",
        "          model_bi[w1][w2] += 1\n",
        "  freq_l = []\n",
        "  for w1 in model_bi:\n",
        "      for w2 in model_bi[w1]:\n",
        "          freq_l.append({str(w1)+\" \"+str(w2):model_bi[w1][w2]})\n",
        "  return freq_l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtxtYbLz8CF7"
      },
      "source": [
        "res_bigram = generate_bigrams(docm_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dx0_ez2_mi9"
      },
      "source": [
        "res_bigram_srt = sorted(res_bigram, key = lambda i: next(iter(i.values())),reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAK3EF5qKGaW",
        "outputId": "07a36e5c-7df8-4d0d-9af3-46e9eadffaec"
      },
      "source": [
        "res_bigram_srt[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{', and': 7555},\n",
              " {'. ]': 6765},\n",
              " {', I': 4460},\n",
              " {', And': 3742},\n",
              " {', [': 2773},\n",
              " {', my': 2251},\n",
              " {'[ Enter': 2177},\n",
              " {'I am': 1962},\n",
              " {\"I 'll\": 1854},\n",
              " {'I have': 1707}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlI8woYfy_RY"
      },
      "source": [
        "\n",
        "b) Write a function to generate all unique trigrams from all documents in the dataset. The\n",
        "input of this function should be the concatenated dataset and the output should be the\n",
        "list of trigrams and their frequency. Display the top 10 most common trigrams and their\n",
        "frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4TOveDzzCLi"
      },
      "source": [
        "def generate_trigrams(sentences):\n",
        "  corpus=[]\n",
        "  for sentence in nltk.sent_tokenize(sentences):\n",
        "    corpus.append(nltk.word_tokenize(sentence))\n",
        "\n",
        "\n",
        "  model_tri = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "  \n",
        "  for sentence in corpus:\n",
        "      for w1, w2, w3 in trigrams(sentence):\n",
        "          model_tri[(w1, w2)][w3] += 1\n",
        "  \n",
        "  freq_l = []\n",
        "  for w1_w2 in model_tri:\n",
        "      total_count = float(sum(model_tri[w1_w2].values()))\n",
        "      for w3 in model_tri[w1_w2]:\n",
        "          freq_l.append({str(w1_w2[0])+\" \"+str(w1_w2[1])+\" \"+str(w3):model_tri[w1_w2][w3]})\n",
        "\n",
        "  return freq_l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRuGsYPUTZXz"
      },
      "source": [
        "res_trigram = generate_trigrams(docm_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPpxvLYWU_EX",
        "outputId": "9f0aa33c-18a0-4233-eb4e-a476b0c9da7f"
      },
      "source": [
        "res_trigram[1000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Play ====================== Four': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_-bEhuCTZX0"
      },
      "source": [
        "res_trigram_srt = sorted(res_trigram, key = lambda i: next(iter(i.values())),reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPeGCBVLTZX1",
        "outputId": "ac101f3c-fcfd-4563-f4de-79a07390618c"
      },
      "source": [
        "res_trigram_srt[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{', sir ,': 991},\n",
              " {'exits . ]': 986},\n",
              " {'exit . ]': 970},\n",
              " {', my lord': 957},\n",
              " {', [ to': 876},\n",
              " {', [ as': 717},\n",
              " {'======= [ Enter': 630},\n",
              " {', [ aside': 627},\n",
              " {\"' th '\": 580},\n",
              " {'[ They exit': 570}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc76KIbEzBQN"
      },
      "source": [
        "\n",
        "c) Write a function to extract all unique NOUN and VERB tokens. The input of this function\n",
        "should be the concatenated dataset and the output should be two lists: one of the NOUN\n",
        "tokens and their frequency, the other list should be the VERB tokens and their counts.\n",
        "Display the top 10 most common NOUN and VERB tokens.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0-2bb5nZu5q"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwqxGIVtccHw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Fr7kRLzFqn"
      },
      "source": [
        "def pos_tag(data_st):\n",
        "  noun = []\n",
        "  verb = []\n",
        "  dv = defaultdict(lambda: 0)\n",
        "  dn = defaultdict(lambda: 0)\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  for i in nltk.sent_tokenize(data_st):\n",
        "    # nlp.max_length = len(data_st)\n",
        "    doc = nlp(i)\n",
        "    for token in doc:\n",
        "      if token.pos_ == 'VERB':\n",
        "        dv[token.text] += 1\n",
        "      elif token.pos_ == 'NOUN':\n",
        "        dn[token.text] += 1\n",
        "  for key in dv:\n",
        "    verb.append((key,dv[key]))\n",
        "  for key in dn:\n",
        "    noun.append((key,dn[key]))\n",
        "  return noun,verb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wly6rlFWcYfx"
      },
      "source": [
        "n,v = pos_tag(docm_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aPZXglPiw7k"
      },
      "source": [
        "v_srt = sorted(v, key = lambda i: i[1],reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyDm6V62e6mm"
      },
      "source": [
        "n_srt = sorted(n, key = lambda i: i[1],reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1puyOerekAc",
        "outputId": "4c827490-f9fc-4c50-e5f2-1f8b13586b65"
      },
      "source": [
        "print(\"Top 10 most common Nouns :\")\n",
        "print(n_srt[:10])\n",
        "print(\"Top 10 most common Verbs :\")\n",
        "print(v_srt[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 most common Nouns :\n",
            "[('man', 2000), ('love', 1575), ('sir', 1236), ('heart', 1099), ('time', 1080), ('father', 1021), ('men', 970), ('life', 933), ('hand', 926), ('death', 877)]\n",
            "Top 10 most common Verbs :\n",
            "[('will', 4449), ('shall', 3349), (\"'ll\", 2598), ('would', 2166), ('can', 1901), ('know', 1680), ('Enter', 1640), ('make', 1578), ('come', 1566), ('may', 1546)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vzxSWoVzGHJ"
      },
      "source": [
        "d) What do you think the most common bigrams and trigrams could be useful for? There is\n",
        "a particular method we have seen in this class to characterize a corpus that could benefit\n",
        "from having these bigrams/trigrams when the underlying text corpus can’t be shared.\n",
        "Please talk about this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "repnV3aDSWZh"
      },
      "source": [
        "The most common bigrams and trigrams could be used for finding something like most similar words. For example a word like german shepherd is most likely to appear with a word like dog and so is dachshund. This will help us to deduce the words with common bigrams could posses some similarity. As language is sequence dependent, it becomes quite useful to deduce the most commonly occuring sequence of terms as  the bigram or trigram probabilities could encode some syntactic facts. For example a word like \"loves\" is most likely to follow a pronoun or a noun. That means this will also help in finding the parts of speech in a given sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbkSJU-vkE-g"
      },
      "source": [
        "# **Question 4) (30 points)**\n",
        "Using the dataset: Ask0729, found in Exam files, write two functions to\n",
        "extract all dates found in this dataset. The input of these functions should take the dataset as\n",
        "input, and output a list of dates. You should use two different methods, one per function.\n",
        "\n",
        "a) First method: using SpaCy (this is a big enough hint)\n",
        "\n",
        "b) Second method: using regular expressions.\n",
        "\n",
        "c) Print to screen to compare the results from the two functions.\n",
        "\n",
        "d) Which one of the two approaches was better? Why do you think so? \n",
        "Would you use any\n",
        "of these approaches? Or a different one?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGi4ivdnkWSE"
      },
      "source": [
        "q4_data = pd.read_csv('/content/drive/MyDrive/exam2/Ask0729/Ask0729-fixed.txt', delimiter = \"\\t\",header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "nHqDXi-vlEHV",
        "outputId": "9e19191d-1fd5-4fd8-f407-989c3484d772"
      },
      "source": [
        "q4_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No</td>\n",
              "      <td>&gt;&gt;&gt; [1]Contact Me Now to Make $100 Today!$LINK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No</td>\n",
              "      <td>Act now to keep your life on the go!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No</td>\n",
              "      <td>Choose between $500 and $10000 dollars with up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No</td>\n",
              "      <td>Click above to earn today.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No</td>\n",
              "      <td>Click here to receive your first $10 today:</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0                                                  1\n",
              "0  No     >>> [1]Contact Me Now to Make $100 Today!$LINK\n",
              "1  No               Act now to keep your life on the go!\n",
              "2  No  Choose between $500 and $10000 dollars with up...\n",
              "3  No                         Click above to earn today.\n",
              "4  No        Click here to receive your first $10 today:"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG8MkQegpSnD"
      },
      "source": [
        "#**spacy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou2kkRwAlW5m"
      },
      "source": [
        "def spacy_dates(df):\n",
        "  dates=[]\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  for i in df:\n",
        "    # print(i)\n",
        "    doc = nlp(i)\n",
        "    for ent in doc.ents:\n",
        "      if ent.label_ == \"DATE\":\n",
        "        dates.append(ent.text)\n",
        "  return dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFv8ZTBTn3xd"
      },
      "source": [
        "d_a = spacy_dates(q4_data.iloc[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lKXVtAnpG5d",
        "outputId": "20c5ddd1-531b-4e0b-a395-9f73fa7b3b5e"
      },
      "source": [
        "len(d_a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1061"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsm6X716pk4M"
      },
      "source": [
        "# **Regex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcNtw7VzpkhR"
      },
      "source": [
        "def regex_dates(df):\n",
        "  regex = ['\\d+\\s\\w+\\s\\d+','(?:(?-i:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*)','(?:(?-i:Mon|Tue|Wed|Fri|Sat|Sun)[a-z]*)']\n",
        "  regex_str = '(?:% s)' % '|'.join(regex)\n",
        "  dates = []\n",
        "  for i in df:\n",
        "    # print(i)\n",
        "    for j in regex:\n",
        "      if re.search(j, i):\n",
        "        dates.append(re.findall(j, i))\n",
        "  return [item for i in dates for item in i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNMvCMvNvghd"
      },
      "source": [
        "d_b = regex_dates(q4_data.iloc[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKd0GYkyvnG9",
        "outputId": "bb23f56e-c471-4b07-cf80-560f372d4bb4"
      },
      "source": [
        "len(d_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEN75jmB-r4u",
        "outputId": "b024e0f2-371c-43ce-b866-7cc006da2baa"
      },
      "source": [
        "print(\"Spacy dates: \")\n",
        "print(d_a)\n",
        "print(\"Regular expression dates: \")\n",
        "print(d_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spacy dates: \n",
            "['up to 5 years', 'today', 'today', 'today', 'one week', 'MA 02143', 'daily', 'today', '3+ Nights &', 'this week', 'weekend', 'this week', '2 Weeks', 'the day', 'the year', 'tomorrow', 'the 1st and', 'Wednesday', 'Saturday', 'the 6 year old', 'tomorrow', '25 years', 'year end 2000', '40', 'junior-year', 'all summer', 'next week', 'yesterday', 'Monday', 'Thursday', 'July 31, 2014', '30 June 2012', 'April 15th', 'this year', 'this time', 'next year', 'years', 'Friday', 'Monday', 'December 7th', 'yesterday', 'yesterday', 'tomorrow', '14 day', '2 days', 'years', 'tomorrow', 'tomorrow', 'tomorrow', 'the next year', 'Sunday', 'a day', '12 MONTHS', 'July 4, 2012', 'Tomorrow', 'this week', 'Tuesday, March 20, 2001', 'annual', '21st Century', 'this week', '4', 'tomorrow', 'next Wednesday', 'the old days', 'Next week', 'April', 'the 19th', 'August 31st', 'the year', 'only a week', 'June 23, 2000', 'this weekend', 'today', 'Last week', 'Friday', 'the week', 'the 31st of March', '1 Year', 'Thanksgiving', 'Today', 'Tomorrow', '2 weeks ago', 'every day', 'day', 'weekly', 'annual', 'tomorrow', 'A few weeks ago', 'this week', '1999', '2000', 'annual', '2081', 'Monday', 'March 8, 2013', 'the late 18th century', 'last week', 'today', 'next week', 'Sunday', 'the next two weeks', 'a few weeks', 'today', '1850-1940', 'February 28, 2014', 'the last year', 'the weeks', 'months ahead', '2 day', 'today', 'winter', '30 June', 'the next 75 days', '2000', 'about a month', \"last Tuesday'Wednesday's\", 'Thursday', 'this year', '11 July', '1 year', 'April 2011', 'Day 5', 'April 5-19 15,000/day', 'April', 'Wednesday, June 27', 'the first weekend', 'April', 'Jan 26th', 'the weekend', 'the week of January 15th', 'that week', 'friday', 'yesterday', 'Thursday', 'approximately 2 years', 'the next 3-6 months', 'yesterday', 'August 2013', 'August 22, 2012', 'August 23, 2012', 'August 8, 2012', 'this Monday, September 2nd, 2013', 'Autumn Nights', 'a week or so ago', 'Friday', '2001', 'today', 'tomorrow', 'last week', 'tomorrow', 'yesterday', 'Monday', 'Tuesday', 'the days/weeks ahead', 'Thursday', '36 months', 'Wednesday', 'Christmas', 'Thursday', 'Tuesday, October 24 - available', 'daily', 'August', \"Dec. '95\", \"Dec. '95\", 'today', 'tomorrow', 'Wednesday, July 31, 2013', 'the 16th of August', 'Monday, January 14, 2013', 'Friday', 'Friday', 'the first two days', '17 days ago', 'Nov. 8, 2000', 'today', 'the end of the month', 'five-year', 'May 16th', '7', 'quarterly', 'April 16', '2001', 'the school year', 'Weekly', 'Monday, April 23rd', 'Weekly', 'Monday, January 29', 'Thursday, June 14, 2001', 'St 65', 'Friday', 'Friday', 'Friday', 'Christmas', 'July', 'tomorrow', 'tomorrow', 'August', 'the week of April 16', 'April 16, 17', '18 or 19th', 'today', 'Thursday', 'tomorrow', 'today', 'the 13th and 14th', 'tomorrow', 'Monday', 'another month', 'weeks', 'mid-May', 'today', 'tomorrow', 'this week', 'next week', 'this week', 'the day', 'tomorrow', 'today', 'this weeks', 'Monday', 'the past few winters', 'tomorrow', 'tomorrow', 'today', 'tomorrow', 'this week', 'next week', 'next week', 'early November', 'tomorrow', 'this season', 'yesterday', 'a day', 'days', 'today', 'quarter this year', 'Monday', 'Tuesday', 'Monday', 'tomorrow', 'Thursday', 'today', 'tomorrow', 'Tuesday', 'today', 'next week', 'several business days', 'today', 'today', '36', 'half days', 'next week', 'tomorrow', 'next week', 'this summer', 'Nov. 29', 'a couple of weeks', 'today', 'yesterday', 'Wednesday, October 25', 'later this week', 'next week', 'the day', 'tomorrow - deal 169576', 'tomorrow', 'last year', 'Friday', 'July', 'the 16th', 'no quarter', 'the next 60-90 days', 'one month', 'today', 'last week', 'today', 'this week', 'all day', 'tomorrow', 'next week', 'the week', 'tomorrow', 'about 10 days', 'this week', 'today', 'February', 'monthly', 'next week', 'every day', 'the next couple of hours', 'Friday', 'end of day', 'today', 'Monday', 'tomorrow', 'Wednesday', 'Monday', 'today', 'today', '9 years', 'the next ten days', 'January', 'December', 'daily', 'GoHealthInsurance', 'January 16, 2013 to January 18, 2013', '3-5800', 'today', 'NY 10010', 'the end of April', 'tomorrow', 'two year', 'this year', 'monthly', 'every month', 'this month', '2 Weeks', 'the 13th', 'the 12th', 'the weeks', 'today', 'Halloween', 'next week', 'December', 'NaNoWriMo 2013', 'the last 6 months', 'each day', 'Monday', 'Wednesday', 'this week', 'July', 'June 2011 13', 'Day 5', 'June', 'an awesome month', 'the last several months', 'Thursday', 'the weekend', 'daily', 'Half-Year', 'July 11', 'deal 202939', '380571', 'LAST DAY TO BOGO', 'LAST DAY TO', 'LAST WEEKEND TO BOGO', 'Last Week', 'Last year', 'every week', 'Wednesday', 'Saturday', 'the 14th of May.', 'a week', 'Aug. 3, 2000', 'March 2011 12: Period Day 1 13:', '7 28', 'Day 1', 'Wednesday, December 31st', 'Monday', 'Monday', 'Monday through Friday', 'Monday, April 16th', 'Monday, August 6th', 'Monday, June 4th', 'Monday, May 14th', 'this week', 'several weeks ago', 'Feb. 20, 2001', 'the Tuesday', 'the first quarter', 'January', 'today', 'this week', 'Feb 26, 2013', 'Friday, October 26, 2001', 'July 3, 2012', 'May 3rd', 'November 3', 'the days', 'Saturday', '30 days', 'One Week to Christmas', 'One day', 'Friday, May 25', 'tomorrow', 'the last several years', 'a few weeks ago', 'Monday', 'Tuesday, October 2 4, 2000', '1 year', 'Monday January 29, 2001', 'the week of the 11th', 'tomorrow', 'Monday', 'monthly', 'today', 'Friday', 'Tuesday, June 12, 2001', '7 days', 'every month', 'Thursday', 'next week', 'Saturday', 'HE15-19', 'Monday', 'next week', 'Friday', 'Saturday January 19, 2002', 'Saturday', 'Monday', 'Sunday', 'Friday, April the 27th', 'Monday', 'tomorrow', 'tomorrow', 'last Thursday', 'September 4, 2011', 'Wednesday', 'the fall', 'Thursday', 'Sunday 28 August 2011', 'hundreds of years ago', 'the football season', 'tomorrow', 'yesterday', 'this year', 'tomorrow', 'Tomorrow', 'August 21, 2001', 'next summer', 'today', 'tomorrow', 'today', 'Monday, December 16th, 2013', 'tomorrow', 'Friday the 15th', 'Nov. 15th', 'Dec. 1', 'Wednesday', 'Wednesday', 'this week', 'Friday', 'next week', 'this week', 'yesterday', 'tomorrow', 'tomorrow', 'tomorrow', 'Wednesday', '33462', '33464', '33491', '33492', 'Feb. 8', 'Wednesday, August 28th', 'yesterday', 'the end of next week', 'August 18th', 'Sunday, July 14th', 'Four Weeks', '4 Weeks', '1-Hour', 'next day', 'nightly', 'tomorrow', '2001', 'April 2010', 'this week', 'Sunday', 'tomorrow', 'today', '1989', '1989', 'October 17, 2013', 'tomorrow', 'next week', 'next week', 'This Friday', 'Saturday', '251415618', 'today', 'Friday', 'July 28 - August 4, 2001', 'Monday', 'every single day', 'the weekend', 'summer', 'This month', 'later this quarter', 'This week', '72', 'This week', 'Halloween', 'This week', 'This weekend', '2001', '2001', 'This year', 'today', '3:45pm - 10:00pm', 'Today', 'Today', 'Today', 'Today', 'Today', 'Today', 'Tomorrow', 'Wednesday', 'Thursday', 'Friday', 'Tomorrow', 'this week', 'year 2001', 'this week', 'today', 'Two Weeks', 'the next couple of weeks', 'this summer', '6 years', 'Thursday', 'Thursday & Friday', 'Thursday, January 25, 2001 08:36 AM?ET', 'Sept. 11', 'Thursday, September 19th', 'each day', 'daily', 'Saturday', 'between the days', 'July', 'Friday', 'Thursday', 'today', 'tomorrow', 'Thursday', 'later this week', 'tomorrow', 'this month', 'daily', 'monthly', 'this week', 'next week', 'Wednesday', '01&prudent', 'the past few months', \"this current year's\", 'a couple of days', 'Thursday', '2014-07-01', 'this week', 'next week', 'Wednesday', 'Labor Day', 'Friday of this week', 'Monday', 'this weekend', 'Monday 5 November', '19.30', '1201', '7 FREE days', 'this day', 'tomorrow', 'these last few weeks', 'Wednesday, August 2nd', 'last week', 'January', 'the new day', 'summer', 'maybe weeks', 'the coming decade', 'the coming decade', 'year', 'winter', 'the coming year', 'the next 3 business days', 'four weeks', 'the winter', 'the next week', 'Tuesday', 'a couple of weeks', 'tomorrow', 'daily', '1 Dec 2013', '30 day', 'Sunday 29 April 2012', 'January 31, 2013', 'Monday', 'today', 'today', 'Thursday, 31st January', 'the 29th', 'this week', 'today', 'today', 'Tuesday', 'each day', 'this week', 'may 1', 'may 2', '978/281-0744', '2 weeks', 'next week', 'Sept. 11', 'today', 'yesterday', 'weekly', '7 days', 'tomorrow', 'Sunday', 'another 30 days', 'Friday', 'Friday', 'Thursday June 20', 'January', 'Monday, October 8, 2001', 'the month of November', 'Sept. 20', 'tomorrow', 'Thursday', 'Friday', 'today', 'Sunday, December 8th, 2013', 'Monday, November 11th', 'Wednesday, September 25th', '415)244-6094', 'tomorrow', 'this June', 'Tuesday', 'the end of September', 'September 25', 'Thursday', '14 day', 'today', 'today', 'Halloween', 'today', 'tomorrow', 'tomorrow', 'this week', 'Tuesday', 'today', 'Monday', 'the day on Monday or Tuesday', 'Saturday', 'Monday', 'Friday', 'tomorrow', 'Friday', 'this school year', '1-877', 'This week', 'Wednesday', 'Wednesday', 'each day', '2001', 'up to 3 years', 'Thursday', 'today', 'Monday', 'this week', 'Tuesday', 'this Sunday', 'today', 'the beginning of the month', 'Saturday, March 25', 'this weekend', '713/853-5984', '713/853-6440', 'weekly', 'tomorrow', 'daily', 'the past several months', 'Saturday', 'December 7', 'this week', 'Monday', 'Tuesday, January 8th', 'next week', 'Thursday', 'about Friday', 'tomorrow', 'this weekend', 'Thursday, March 22', 'tomorrow', '30 days', 'tomorrow', 'next week', 'tomorrow', 'this week', 'November', 'tomorrow', '1130', 'the weekend', 'today', 'Friday', 'daily', 'October 11th', 'this week', 'the 18th', 'Friday', 'Monday', 'November', 'this week', 'Tuesday', 'Tuesday', 'Wednesday', 'Tuesday', 'tomorrow', '2 day', 'Friday', 'Monday', 'last weekend', 'Monday', 'Jan 2000', 'yesterday', 'daily', 'this week', 'next week', 'that day', 'Tuesday, February 20, 2001', 'Tuesday', 'the weekend', '87-7449', 'today', 'Friday', '2001', 'tomorrow', 'July', 'Sunday', 'tomorrow', 'a year anniversary', 'the following week', 'today', 'early next week', 'March', 'March 28th', 'next week', 'tomorrow', 'tomorrow', 'tomorrow', 'Friday', 'next week', 'Monday, June 4th', 'all day', 'tomorrow', 'the end of the week', 'tomorrow', 'the end of the day', 'Monday', 'December 9', 'next Monday', 'tomorrow', 'the week', 'tomorrow', 'Thursday the 2nd', 'today', 'this weekend', 'next week', 'next week', 'either day', 'this weekend', 'the day and tomorrow', 'Thursday, November 29th', 'between now and Thursday', 'the week', 'next week', 'November 5th', 'today', 'this weekend', 'next week', 'this week', 'the next week', 'a couple days this week', 'next week', 'this week', 'tomorrow', 'a few weeks ago', 'Sunday', 'Monday', 'next week', 'Thursday', 'Wednesday', 'Thursday', 'this week', 'today', 'tomorrow', '3-0977', 'last Thursday', 'tomorrow', 'Thursday', 'Thursday', 'Friday', '3 nights', 'sunday', 'March', '21 years old', 'December', 'today', '251408768', 'Tuesday, August 27th, 2013', 'Friday', 'Friday', 'between May 6 and May 24', 'between November 11th and December 2nd, 2013', 'November 1, 2001', 'Monday, November 20th', 'a couple weeks', 'tomorrow', 'Monday, Jan. 22nd', 'Wednesday, Jan. 24th', 'today', 'the next few business days', 'some days/time', 'the next couple of weeks', 'Sunday earlier', 'Friday, August 17', 'Thursday', 'next week', 'last week', 'XXXXXXXXX2159', 'Wednesday', 'April 12th', '2:30pm', 'Dec 2000', 'March', 'Monday', '2001', 'Thursday', 'Friday', 'Monday', 'Tuesday', 'tomorrow', 'daily', 'tomorrow (Sunday', 'today', 'next week', 'every Friday', 'Wednesday', 'Tuesday', 'tomorrow', 'Friday', 'later this week', 'a few days', 'every week', 'this week', 'Sunday', 'Thursday', 'April 30', 'tomorrow', 'Friday', '2001', 'this next week', 'Saturday', 'Sunday', 'Tuesday', 'next week', 'next Monday', 'tomorrow', 'a later date', 'tomorrow', 'Friday', '02325', 'tomorrow', 'today', 'about the weekend of', 'next week', 'last week', 'Monday', 'next Wednesday', 'Thursday', 'Saturday', '2000', 'Friday', 'two weeks', 'quarterly', 'Monday', 'late Oct.', 'today', 'tomorrow', 'tomorrow', 'Friday', 'the next few days', 'tomorrow', 'next week', 'annual', 'May 12, 2001', 'tomorrow', 'Monday', 'tomorrow', 'Monday', 'next week', 'Sunday', 'Thursday', 'Wednesday', 'Monday', 'Wednesday', 'Monday', 'today', 'Monday', 'next week', '10/31', 'Monday, December 18', 'Intra-month', 'the holidays', 'next Monday', 'the end of the week', 'tomorrow', 'last week', 'Wednesday', 'next week', 'Wednesday, Dec. 13th', 'tomorrow', 'summer', 'April', 'May', 'summer', 'next week', 'Monday', 'Monday', 'tomorrow', 'Friday', 'Monday', '627-8172', 'next Tuesday/Wednesday', 'Thursday', 'between now and Monday', 'Friday', 'a day', 'Sunday', 'December', 'today', 'next week', '301/652-7877', 'tommorrow', 'today', 'tomorrow', 'Monday', 'Saturday', 'Friday', 'Friday', 'the next week', 'March 12', 'this week', 'Saturday', 'last Sunday', 'Labor Day', 'January 2001', 'the 17th', 'today', 'Christmas', 'tomorrow', 'season', 'season', 'today', 'tomorrow', 'Christmas', 'Friday, August 4th', 'this coming Monday', 'every other week', 'a week and a half', 'tomorrow', 'monthly', 'last week', 'Thursday', '7-10', '1100', 'Monday', 'two days', 'Wednesday', 'Thursday', '2014', 'Tuesday, September 30th', 'January', 'these days', 'this week', 'Thursday', 'next week', 'early next week', 'Monday', 'one day', '2000', 'this week', 'yesterday', 'the weekend', 'Monday', 'next week', 'the following week', 'next week', 'Tuesday', 'this week', 'the end of January', 'mid January', 'Wednesday', 'Thursday', 'early October', 'the next couple weeks', 'Friday', 'early next week', 'today', 'this weekend', 'this weekend', 'next summer', 'today', 'Week 2013', 'the next month', 'April 16', 'Monday', 'today', '15s', 'this week', 'today', 'next Monday', 'Thursday', 'all next week', 'next week', 'the next many months', 'September 5, 2000', 'tomorrow', 'weekly', 'Friday', 'weekly', 'this week', 'Dec. 17th', 'Thursday', 'this weekend', '2000', 'year', 'tomorrow', 'Thursday, November 28', 'Monday', 'tomorrow', 'that day', 'this week', 'monthly', 'tomorrow', 'tomorrow', 'next week', 'next year', 'this week', 'tomorrow', 'the next few weeks', 'Sunday', 'Saturday', 'April 11', 'same week', 'Saturday', 'Tuesday the 24th', 'Sunday', 'the next couple of days', 'Monday', 'next week', 'the weekend', 'this weekend', 'next Thursday', 'the last several weeks', 'Thursday', 'tomorrow', 'Sunday', 'tomorrow', 'the 25th - 28th', 'the 28th', 'tomorrow', 'Wednesday']\n",
            "Regular expression dates: \n",
            "['30 on 3', 'Jane', 'Wednesday', 'Saturday', 'Monday', 'July', '30 June 2012', 'June', 'April', 'Friday', 'Monday', 'December', 'Mark', 'Sunday', 'Maybe', 'July', 'March', 'Tuesday', 'Wednesday', 'April', 'August', 'June', 'Marks', 'Friday', 'March', '1999 and 2000', 'Marketing', 'Monday', 'March', 'Market', 'Sunday', 'February', 'June', 'Tuesday', 'Wednesday', 'July', 'April', 'April', 'April', 'June', 'Wednesday', 'April', 'Martin', 'Jan', 'Sat', 'January', 'Decrease', 'August', 'August', 'August', 'August', 'September', 'Monday', 'Friday', 'Monterrey', 'Monday', 'Tuesday', 'Wednesday', 'October', 'Tuesday', 'August', 'Dec', 'Dec', '0527 Cell 781', '8397 Fax 781', 'July', 'Wednesday', 'August', 'January', 'Monday', 'Friday', 'Friday', 'Market', '27 Jun 14', 'Jun', 'Montana', 'Nov', 'May', 'April', 'Aug', 'Dec', 'April', 'Monday', 'January', 'Monday', 'June', 'Friday', 'Friday', 'Friday', 'July', 'August', '18 or 19', 'April', 'April', 'August', 'Martha', 'Martha', 'Monday', 'May', 'Montali', 'Margaret', 'Monday', '02 Sep 13', 'Sep', 'Monday', 'November', 'Marty', 'Mona', 'Monday', 'Tuesday', 'Monday', '00 to 10', 'Tuesday', 'Wed', 'Nov', 'October', 'Wednesday', 'May', 'June', 'July', 'Frihart', 'Friday', 'Julie', 'Mark', 'February', 'Friday', 'Monday', 'Wednesday', 'Monday', 'Mary', 'Mary', 'Mary', 'January', 'December', 'January', 'January', '20 West 22', 'Marksman', 'April', 'December', 'Monday', 'Wednesday', 'Jana', 'Marty', 'July', 'June', 'June', 'July', 'Sep', 'Wednesday', 'Saturday', 'May', 'Aug', 'March', 'Mark', 'Mark', 'Mark', 'Mark', 'Married', 'Marvelous', 'May', 'December', 'Wednesday', 'Monday', 'Monday', 'Monday', 'Friday', 'April', 'Monday', 'August', 'Monday', 'June', 'Monday', 'May', 'Monday', 'Feb', 'Friend', 'Mary', 'Tuesday', 'January', 'Feb', 'October', 'Friday', 'July', 'May', 'November', 'Monterrey', 'Saturday', 'May', 'Friday', 'Monday', 'October', 'Tuesday', '3571 x 1910', 'January', 'Monday', 'Monday', 'Friday', 'June', 'Tuesday', 'Friedman', 'Saturday', 'Monday', 'Friday', 'January', 'Saturday', 'Saturday', 'Monday', 'Sunday', 'April', 'Friday', 'Monday', 'Monday', 'September', 'Wednesday', '28 August 2011', 'August', 'Sunday', 'August', 'December', 'Monday', 'Friday', 'Nov', 'Dec', 'Wednesday', 'Wednesday', 'Friday', 'Marty', 'Sunde', 'Wednesday', 'Mary', 'Feb', 'August', 'Wednesday', 'August', 'July', 'Wedding', 'Sunday', 'April', 'Sunday', 'October', 'Wed', 'Friday', 'Saturday', 'June', 'July', 'August', 'Friday', '07 PM 06', 'Monday', '72 or 77', '2011 from 3', 'Sat', 'Wednesday', 'Friday', 'Friday', 'January', 'Sept', 'September', 'Montgomery', 'Saturday', 'Tues', 'July', 'Friday', 'Wednesday', 'Wednesday', 'Mark', 'Friday', 'Monday', 'November', 'Monday', 'Mont', 'August', 'Wednesday', 'January', 'Nov', 'Monitor', 'Mon', 'Tuesday', '1 Dec 2013', 'Dec', 'Sun', '29 April 2012', 'April', 'Sunday', 'January', 'Monday', 'January', '26 Jun 14', 'Jun', 'Montrond', 'Tuesday', 'Tues', 'Sept', 'Sunday', 'Friday', 'Friday', 'Janet', 'June', 'May', 'January', 'October', 'November', 'Monday', 'Sept', 'Friday', 'December', 'Sunday', 'November', 'Monday', 'September', 'Wednesday', 'June', 'Tuesday', 'September', 'September', 'Tuesday', 'Monday', 'Monday', 'Tuesday', 'Saturday', 'Monday', 'Friday', 'Friday', 'Mario', 'Mark', 'Wednesday', 'Wednesday', 'Weds', 'Monday', 'Friday', 'Tuesday', 'Sunday', 'March', 'Saturday', 'Mary', 'Saturday', 'December', 'Monday', 'Mark', 'January', 'Tuesday', 'Friday', '30 or 12', 'March', 'November', 'Marissa', 'Friday', 'Apr', 'October', 'Friday', 'Monday', 'November', 'Tuesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Sept', 'Monday', 'Friday', 'Monday', 'Monday', 'Jan', 'February', 'Tuesday', 'Marston', 'Tuesday', 'Friday', 'July', 'Sunday', 'March', 'March', 'Friday', 'June', 'Monday', 'Monday', 'December', 'Monday', 'Mary', 'Tuesday', 'Tueday', 'November', 'Mark', 'November', '2887 or 713', 'Mark', 'Janelle', 'Julie', 'Mark', 'Sunday', 'Monday', 'Wednesday', 'Mark', 'Mark', 'Marylyn', 'Maybe', 'Maybe', 'Maybe', 'Friday', '01 at 9', 'Tues', 'March', 'December', 'Janette', '251408768 through 11', 'August', 'Tuesday', 'Friday', 'Friday', 'May', 'May', 'November', 'December', 'November', 'Mark', 'November', 'Monday', 'Jan', 'Jan', 'Monday', 'Wednesday', 'Sunday', 'August', 'Friday', 'April', 'Wednesday', 'Janette', 'Janette', 'Dec', 'March', 'Monday', '713 853 3848', 'Friday', 'Monday', 'Tuesday', 'Sunday', 'Marketing', 'Friday', 'Wednesday', 'Tuesday', 'Friday', 'Sunday', 'April', 'Friday', 'Monday', 'Saturday', 'Sunday', 'Tuesday', 'Monday', 'Friday', 'Fri', 'Monday', 'Wednesday', 'Saturday', 'Friday', 'Monday', 'Oct', 'Friday', 'May', 'Monday', 'Monday', 'Sunday', 'Wednesday', 'Monday', 'Wednesday', 'Monday', 'Monday', 'December', 'Monday', 'Monday', 'Monday', 'Wednesday', 'Dec', 'Wednesday', 'Sunday', '3 or 4', '1 or 2', 'April', 'May', 'Mark', '22 Apr 14', 'Apr', 'Monday', '7 at 888', '26 Jun 14', 'Jun', '21 Apr 14', 'Apr', 'Monday', 'Friday', 'Monday', '7 at 855', 'Tuesday', 'Wednesday', 'Monday', 'Friday', 'December', 'Sunday', 'Monday', 'Mark', 'Janel', 'Monday', 'Saturday', 'Friday', 'Friday', '12 at 10', 'March', 'Saturday', 'Sunday', 'Mark', 'January', 'Wednesday', 'Mark', 'August', 'Friday', 'Monday', 'Monday', 'Wednesday', 'September', 'Tuesday', 'January', 'Monday', 'Monday', 'Martha', 'Tuesday', 'January', 'January', 'Wednesday', 'October', 'Friday', '0989 Extension 4864', 'April', 'Monday', 'Wed', 'Mark', 'Monday', 'Janet', 'September', 'Mark', 'Mark', 'Maybe', 'Friday', 'Dec', 'Wednesday', 'November', 'Monday', 'Saturday', 'September', 'Satisfaction', 'Sunday', 'Saturday', 'April', 'Saturday', 'Tuesday', 'Sunday', 'Monday', 'Sunday', 'Feb', '5 to 10', 'Mary', 'Dec', 'Wednesday']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeUBNlvia-ge"
      },
      "source": [
        "Which one of the two approaches was better? Why do you think so? Would you use any of these approaches? Or a different one?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFUdODTxbAms"
      },
      "source": [
        "I find using spacy as a better approach as it is more efficient to use the spacy's trained pipline for NER rather than writing regular expressions for every form of date present in the text. Regex becomes more tedious when we need to find the required expression which is not in a definite form and also it is not a model that has some understanding of what could follow or occur before a word/key/number to make it a relevant date instance in the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3XFSoUo_VpG"
      },
      "source": [
        "# **Question 5) (30 points)**\n",
        "Train an LSTM model to classify the Cornell Movie Review data\n",
        "using the polarity_dataset V2.0. You can use the code for class 19, but take a note that\n",
        "you will have to adapt some of the parameters like: Review size = 450, epochs=5. You will use\n",
        "85% of the dataset for training, and 15% for testing. Once you build the model, please display\n",
        "the sklearn classification report. What are you noticing here? Anything unexpected? How does\n",
        "this model compare to the one built with the IMDB dataset in class? Any ideas on how to\n",
        "improve it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxboQT_A_dhx"
      },
      "source": [
        "def file_extract(data,dir):\n",
        "  path = '/content/drive/MyDrive/exam2/txt_sentoken/'\n",
        "  path += dir\n",
        "  with os.scandir(path) as files:\n",
        "    for file in files:\n",
        "      if file.name.endswith(\".txt\"):\n",
        "        with open(path+\"/\"+file.name) as review:\n",
        "          data = data.append({'data':review.read(),'labels':dir,'name':file.name},ignore_index=True)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYzKOLoFBG6e"
      },
      "source": [
        "q5_data = pd.DataFrame()\n",
        "q5_data = file_extract(q5_data,\"neg\")\n",
        "q5_data = file_extract(q5_data,\"pos\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "AQhjcwI1GVqL",
        "outputId": "0635335b-5ed1-4eed-ad26-6ee28adcddd8"
      },
      "source": [
        "q5_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>labels</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>before the remake of psycho appears , we've go...</td>\n",
              "      <td>neg</td>\n",
              "      <td>cv080_14899.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" there will be another , \" the ads for this ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>cv072_5928.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>there's a 1 , 000-foot tidal wave at the end o...</td>\n",
              "      <td>neg</td>\n",
              "      <td>cv071_12969.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>for better or worse , the appearance of basic ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>cv074_7188.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\" virus \" is the type of cliched , vacuous fi...</td>\n",
              "      <td>neg</td>\n",
              "      <td>cv078_16506.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>ingredients : down-on-his-luck evangelist , ch...</td>\n",
              "      <td>pos</td>\n",
              "      <td>cv923_11051.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>when i first saw the previews for ron howard's...</td>\n",
              "      <td>pos</td>\n",
              "      <td>cv940_17705.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>armageddon , in itself , symbolizes everything...</td>\n",
              "      <td>pos</td>\n",
              "      <td>cv932_13401.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>there are some works of art that are almost im...</td>\n",
              "      <td>pos</td>\n",
              "      <td>cv930_13475.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>in zoolander , the world's most successful , i...</td>\n",
              "      <td>pos</td>\n",
              "      <td>cv920_29622.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   data labels             name\n",
              "0     before the remake of psycho appears , we've go...    neg  cv080_14899.txt\n",
              "1      \" there will be another , \" the ads for this ...    neg   cv072_5928.txt\n",
              "2     there's a 1 , 000-foot tidal wave at the end o...    neg  cv071_12969.txt\n",
              "3     for better or worse , the appearance of basic ...    neg   cv074_7188.txt\n",
              "4      \" virus \" is the type of cliched , vacuous fi...    neg  cv078_16506.txt\n",
              "...                                                 ...    ...              ...\n",
              "1995  ingredients : down-on-his-luck evangelist , ch...    pos  cv923_11051.txt\n",
              "1996  when i first saw the previews for ron howard's...    pos  cv940_17705.txt\n",
              "1997  armageddon , in itself , symbolizes everything...    pos  cv932_13401.txt\n",
              "1998  there are some works of art that are almost im...    pos  cv930_13475.txt\n",
              "1999  in zoolander , the world's most successful , i...    pos  cv920_29622.txt\n",
              "\n",
              "[2000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "GeODkzeRGh_2",
        "outputId": "dc649e9c-d600-46c5-e57f-8d6630cda55b"
      },
      "source": [
        "q5_data['labels'] = q5_data['labels'].map({'pos': 1, 'neg': 0}).astype(int)\n",
        "q5_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>labels</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>before the remake of psycho appears , we've go...</td>\n",
              "      <td>0</td>\n",
              "      <td>cv080_14899.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" there will be another , \" the ads for this ...</td>\n",
              "      <td>0</td>\n",
              "      <td>cv072_5928.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>there's a 1 , 000-foot tidal wave at the end o...</td>\n",
              "      <td>0</td>\n",
              "      <td>cv071_12969.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>for better or worse , the appearance of basic ...</td>\n",
              "      <td>0</td>\n",
              "      <td>cv074_7188.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\" virus \" is the type of cliched , vacuous fi...</td>\n",
              "      <td>0</td>\n",
              "      <td>cv078_16506.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>ingredients : down-on-his-luck evangelist , ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>cv923_11051.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>when i first saw the previews for ron howard's...</td>\n",
              "      <td>1</td>\n",
              "      <td>cv940_17705.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>armageddon , in itself , symbolizes everything...</td>\n",
              "      <td>1</td>\n",
              "      <td>cv932_13401.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>there are some works of art that are almost im...</td>\n",
              "      <td>1</td>\n",
              "      <td>cv930_13475.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>in zoolander , the world's most successful , i...</td>\n",
              "      <td>1</td>\n",
              "      <td>cv920_29622.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   data  ...             name\n",
              "0     before the remake of psycho appears , we've go...  ...  cv080_14899.txt\n",
              "1      \" there will be another , \" the ads for this ...  ...   cv072_5928.txt\n",
              "2     there's a 1 , 000-foot tidal wave at the end o...  ...  cv071_12969.txt\n",
              "3     for better or worse , the appearance of basic ...  ...   cv074_7188.txt\n",
              "4      \" virus \" is the type of cliched , vacuous fi...  ...  cv078_16506.txt\n",
              "...                                                 ...  ...              ...\n",
              "1995  ingredients : down-on-his-luck evangelist , ch...  ...  cv923_11051.txt\n",
              "1996  when i first saw the previews for ron howard's...  ...  cv940_17705.txt\n",
              "1997  armageddon , in itself , symbolizes everything...  ...  cv932_13401.txt\n",
              "1998  there are some works of art that are almost im...  ...  cv930_13475.txt\n",
              "1999  in zoolander , the world's most successful , i...  ...  cv920_29622.txt\n",
              "\n",
              "[2000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ_b390xG4s2"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import logging\n",
        "from sklearn.model_selection import train_test_split\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "class_names = [\"Negative\", \"Positive\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8t7g6BmHPTw"
      },
      "source": [
        "a_train,a_test = train_test_split(q5_data, test_size=0.15, random_state=seed_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueUj6t_nHPCg"
      },
      "source": [
        "x_train = []\n",
        "x_test = []\n",
        "for i in a_train.data:\n",
        "    x_train.append(i)\n",
        "for i in a_test.data:\n",
        "    x_test.append(i)\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "y_train = a_train['labels'].values\n",
        "y_test = a_test['labels'].values\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E05AweFu0Imt"
      },
      "source": [
        "# Perform reverse word lookup and make it callable\n",
        "reverse_word_index = dict([(key,tokenizer.index_word[key]) for key in tokenizer.index_word])\n",
        "reverse_word_index[0] = \"<PAD>\"\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index[i] for i in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNYcwMITFHbC",
        "outputId": "d7604fe7-c372-4068-c3d2-85deaf2b0246"
      },
      "source": [
        "# Concatonate test and training datasets\n",
        "allreviews = np.concatenate((x_train, x_test), axis=0)\n",
        "# Review lengths across test and training whole datasets\n",
        "print(\"Maximum review length: {}\".format(len(max((allreviews), key=len))))\n",
        "print(\"Minimum review length: {}\".format(len(min((allreviews), key=len))))\n",
        "result = [len(x) for x in allreviews]\n",
        "print(\"Mean review length: {}\".format(np.mean(result)))\n",
        "\n",
        "# Print a review and it's class as stored in the dataset. Replace the number\n",
        "# to select a different review.\n",
        "print(\"\")\n",
        "print(\"Machine readable Review\")\n",
        "print(\"  Review Text: \" + str(x_train[1]))\n",
        "print(\"  Review Sentiment: \" + str(y_train[1]))\n",
        "\n",
        "# Print a review and it's class in human readable format. Replace the number\n",
        "# to select a different review.\n",
        "print(\"\")\n",
        "print(\"Human Readable Review\")\n",
        "print(\"  Review Text: \" + decode_review(x_train[1]))\n",
        "print(\"  Review Sentiment: \" + class_names[y_train[1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length: 2680\n",
            "Minimum review length: 18\n",
            "Mean review length: 745.7995\n",
            "\n",
            "Machine readable Review\n",
            "  Review Text: [2360, 52, 28232, 5, 6365, 28233, 28234, 177, 99, 1625, 38, 39, 16999, 1220, 1581, 100, 25, 1437, 107, 78, 64, 22, 18, 28235, 7544, 393, 6, 39, 733, 14485, 3, 28236, 1, 355, 1647, 4483, 17000, 7116, 2102, 15, 28237, 437, 1, 9, 2, 5486, 1, 5, 241, 335, 2103, 3, 4642, 52, 1781, 4643, 818, 15, 4, 1781, 293, 1, 5, 2, 31, 156, 68, 6707, 11, 61, 4, 1254, 1968, 2591, 7, 223, 6366, 7545, 1, 12650, 1, 1469, 3, 220, 40, 23, 99, 1141, 9, 463, 7545, 1469, 1, 312, 1, 29, 2137, 40, 3467, 126, 20, 6041, 5, 266, 2, 3468, 3565, 5, 1901, 631, 8057, 330, 3181, 1, 219, 1648, 22, 267, 450, 3, 381, 230, 15, 11, 10, 31, 1, 10, 40, 144, 34, 7, 146, 137, 2, 2061, 599, 6, 334, 6366, 475, 7, 12651, 2494, 20963, 643, 47, 10, 6708, 3, 10, 193, 688, 101, 1969, 9, 2, 31, 3, 4315, 1, 140, 1716, 2275, 9366, 2322, 51, 1261, 2704, 39, 1469, 1, 70, 14486, 39, 733, 142, 2894, 17001, 28238, 6, 2027, 22, 1781, 600, 3, 776, 1581, 1, 7117, 1, 1437, 2062, 632, 4, 245, 9, 4, 8656, 275, 7, 964, 2, 2276, 6, 392, 830, 6709, 100, 20, 74, 10, 102, 4, 1672, 7, 1626, 3, 10, 4022, 3, 21, 31, 908, 7, 1347, 121, 143, 92, 7546, 50, 3, 3669, 12652, 3, 331, 81, 613, 2, 355, 4483, 17000, 1, 993, 6, 20964, 5, 4176, 14487, 77, 4484, 45, 1, 20965, 37, 330, 8657, 15, 1864, 17002, 304, 1, 5, 2102, 77, 8658, 3, 3566, 981, 1, 187, 1, 20965, 752, 39, 2060, 2103, 2651, 13, 12653, 12, 7, 545, 39, 1581, 9, 2, 151, 3, 532, 1, 68, 33, 2761, 2, 31, 3, 11279, 20, 3035, 1254, 592, 1, 1970, 479, 9, 17, 4, 65, 649, 54, 92, 3, 43]\n",
            "  Review Sentiment: 0\n",
            "\n",
            "Human Readable Review\n",
            "  Review Text: synopsis : big-breasted and dim-witted sculptress britt gets really mad at her grad student boyfriend because he spends too much time on his thought-transference experiments instead of her art showings . \n",
            "elderly , evil scientist everett longstreet switches minds with britt's boy , in the meantime , and goes completely mental . \n",
            "comments : naked souls opens with a naked woman , and the movie makes no illusion that it's a sci-fi vehicle designed to show pamela anderson's , um , talents . \n",
            "if you are really interested in seeing anderson's talents , however , i suggest you skip over this dud and watch the infamous pam and tommy lee honeymoon sex tape , now available on home video . \n",
            "at least with that \" movie , \" you don't have to go through the painful experience of watching pamela try to pronounce multiple syllable words like \" eclectic . \" \n",
            "a premise does exist in the movie . \n",
            "basically , while anderson wears skimpy clothes which barely contain her talents , she practices her art -- brilliantly slapping plaster of paris on naked women . \n",
            "her boyfriend , meanwhile , spends 20 hours a day in a morgue trying to view the memories of dead prison inmates because this will \" make a difference to humanity . \" \n",
            "whatever . \n",
            "the movie fails to explain how these two hooked up . \n",
            "be grateful . \n",
            "after we meet the evil everett longstreet , lots of technobabble and mystical mumbo-jumbo get tossed about , pammy has sex replete with cheesy make-out music , and minds get transferred . \n",
            "never fear , though , pammy uses her sharp mental abilities ( ahem ) to save her boyfriend in the end . \n",
            "unfortunately , no one saves the movie . \n",
            "avoid this would-be sci-fi thriller , unless you're in for a good laugh or two . \n",
            "\n",
            "  Review Sentiment: Negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyfQqKod7koB"
      },
      "source": [
        "# The length of reviews\n",
        "review_length =  450\n",
        "# Padding / truncated our reviews\n",
        "x_train = sequence.pad_sequences(x_train, maxlen = review_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = review_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP1MHxzW-lUx",
        "outputId": "a29ae3d8-0a17-47b7-dba2-3addaff08528"
      },
      "source": [
        "print(\"Shape Training Review Data: \" + str(x_train.shape))\n",
        "print(\"Shape Training Class Data: \" + str(y_train.shape))\n",
        "print(\"Shape Test Review Data: \" + str(x_test.shape))\n",
        "print(\"Shape Test Class Data: \" + str(y_test.shape))\n",
        "print(\"Review data\"+str(x_train[60]))\n",
        "print()\n",
        "print(\"Human Readable Review Text (post padding):\\n\" + decode_review(x_train[60]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape Training Review Data: (1700, 450)\n",
            "Shape Training Class Data: (1700,)\n",
            "Shape Test Review Data: (300, 450)\n",
            "Shape Test Class Data: (300,)\n",
            "Review data[   18    96     6 28977   150     8    26  8206   126     2   369   940\n",
            "  2093     3    42    80    47    11     2    19   127   181     4   820\n",
            "   446    38   105     6     2   940  5514    54 28978     1    24    38\n",
            "  2334     9   859     5   121   319     8   471    26     2   790    13\n",
            "   310     2 28979  9553    86    77     4   290  4058    26     2   151\n",
            "     6     2    19    12     3    42   703     6     2  3594    23   351\n",
            "   762     1   135    16     4  5338  6139    11    25  1191    38     4\n",
            " 21362  3277     7    57     3    42  1971     6     2    19     8   335\n",
            "  2500     1    24   257     2   256   232    45    14     3    42   124\n",
            "    28  1515     1   694    19    38     2  2118     1    24     2  3825\n",
            "    11  3227    37   932     8    49    78    48  8207    63   755   636\n",
            "     9     2   569     3    42   317  1287     7    20   648     8  9554\n",
            "  1649     6  2808    88    20     8     4   171    11  1224  4094    22\n",
            "     4  2527  2122     3    43    42  3227     8    49    78   256     7\n",
            "   266   157   142   163   269   196     1    24   163    91  1055     9\n",
            "   801    11  2430    46    18    83   235   306    54  6846  4386  1438\n",
            "     3    43    42  3227     8    49    65    11  2808     1   658    18\n",
            "  6140    16     4   358   125     1     8    28  1007  1753     5  1718\n",
            "    83   200    36     2   527     3    21   512   208     8  3784     5\n",
            "  2524     3    42 28980     8 10449     1    16   269     1     5  1287\n",
            "     7    39 12901     6   896   512   531     3    42  9555  5134    37\n",
            "     4    65   179    16     4   906  3466    30   752 11483 28981     7\n",
            "    86    18  2326   155     3    42 12902  4329     8    28   308    30\n",
            "   184    27  5339     1    17  9556    29   981    25   182 28982     4\n",
            "   577  1407    15     2  2128     6    18   225    13   187   163    84\n",
            "   196     7   266    12     3    42   714  3696  1287     2  2933  1479\n",
            "     7    18  1073     6 12763 21363     3   948  2808  1798    42    42\n",
            "    80  1394    55   182    95    14    11    96     3    42    80   510\n",
            "  4500    26     2    19     1    24   136   237     1    29  1284   480\n",
            "    45  2334     3    42    80   180    11   115    30   198    20    19\n",
            "  1798    74    56    27 28983    26     2  5060     6     2    73     3\n",
            "    42    21    19   194   426     1     6   231   142     2   371   271\n",
            "   246   155    17   117     1     5     2     4   162     6     2   128\n",
            "   166  2808     5  5563   320   617    13   310     2  6708  1473   415\n",
            "     8  1904    12     3    42    87   143    23  1080 17320    45    28\n",
            "  1022   839    19     3    42  9548     8     4   857     1 12903   196\n",
            "   281    11  1117     7   117    11   940  1635    66  8208   258  2447\n",
            "    63     2  1878     3    42    43]\n",
            "\n",
            "Human Readable Review Text (post padding):\n",
            "his way of lashing back is by screwing over the entire political structure . ? \n",
            "i like that the film doesn't take a clear shot at any of the political parties or affiliations , but at politics in general and how everything is run by the rich ( although the anti-rich sentiments do get a bit tiresome by the end of the film ) . ? \n",
            "some of the segments are simply hilarious , such as a lengthy rap that he delivers at a luncheon dedicated to him . ? \n",
            "much of the film is completely absurd , but that's the fun part about it . ? \n",
            "it's an angry , serious film at the core , but the package that beatty has created is so much more accessible than recent attempts in the genre . ? \n",
            "what adds to this feeling is beatty's portrayal of bulworth ; this is a performance that deserves recognition on a higher scale . \n",
            " ? beatty is so much fun to watch here -- he's always funny , but he's also subtle in ways that flesh out his character without dialogue or hugely noticeable actions . \n",
            " ? beatty is so good that bulworth , despite his shortcomings as a human being , is an entirely sympathetic and likable character almost from the beginning . \n",
            "the supporting cast is vast and colorful . ? \n",
            "berry is luminous , as always , and adds to her repertoire of solid supporting roles . ? \n",
            "don cheadle has a good role as a drug dealer who uses gun-toting toddlers to do his dirty work . ? \n",
            "oliver platt is an actor who should be careful , for someday i fear he may induce a heart attack with the intensity of his acting ( though he's very funny to watch ) . ? paul sorvino adds the southern accent to his list of mastered inflections . \n",
            "is bulworth offensive ? ? \n",
            "i suppose some may see it that way . ? \n",
            "i wasn't offended by the film , but then again , i hardly care about politics . ? \n",
            "i think that people who find this film offensive will just be blindsided by the honesty of the story . ? \n",
            "the film isn't perfect , of course -- the ending didn't quite work for me , and the a few of the scenes between bulworth and nina feel forced ( although the eclectic dance sequence is fantastic ) . ? \n",
            "but these are minor quibbles about an otherwise brilliant film . ? \n",
            "bulworth is a smart , uproariously funny picture that proves to me that political satire can scratch far deeper than the surface . ? \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLghhjKo3x1N",
        "outputId": "4afa5135-f314-4221-a79a-7096289754f5"
      },
      "source": [
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nmO8M4aCKwT",
        "outputId": "b840604d-f0e9-4863-aff3-42c3cd758dad"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim = vocab_size,output_dim = 32,input_length = review_length))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.25))\n",
        "model.add(tf.keras.layers.LSTM(units=32))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.25))\n",
        "model.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) # reporting metric\n",
        "\n",
        "# Display a summary of the models structure\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 450, 32)           1665984   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 450, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,674,337\n",
            "Trainable params: 1,674,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB8KhSgl5rfB",
        "outputId": "cc4f3f3f-ee69-4275-a1b4-4e3a43c3686c"
      },
      "source": [
        "history = model.fit(x_train,y_train,batch_size=100,epochs=5,validation_split=0.2,verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "14/14 [==============================] - 7s 345ms/step - loss: 0.6934 - accuracy: 0.5191 - val_loss: 0.6932 - val_accuracy: 0.4882\n",
            "Epoch 2/5\n",
            "14/14 [==============================] - 5s 324ms/step - loss: 0.6914 - accuracy: 0.5709 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
            "Epoch 3/5\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.6843 - accuracy: 0.5721 - val_loss: 0.6817 - val_accuracy: 0.5235\n",
            "Epoch 4/5\n",
            "14/14 [==============================] - 5s 325ms/step - loss: 0.6336 - accuracy: 0.7276 - val_loss: 0.6659 - val_accuracy: 0.6235\n",
            "Epoch 5/5\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.5910 - accuracy: 0.7956 - val_loss: 0.6289 - val_accuracy: 0.7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPnfxwbnITqV",
        "outputId": "c8329cbb-0fb8-4211-eebe-d9b572b6a6ce"
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(x_test)\n",
        "print(classification_report(y_test, predicted_classes, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.69      0.63      0.66       164\n",
            "    Positive       0.59      0.65      0.62       136\n",
            "\n",
            "    accuracy                           0.64       300\n",
            "   macro avg       0.64      0.64      0.64       300\n",
            "weighted avg       0.64      0.64      0.64       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsEjj0bJNCss"
      },
      "source": [
        "import sklearn.metrics as sm\n",
        "def evaluate_model(pred,y):\n",
        "  acc = sm.accuracy_score(y,pred)\n",
        "  pr = sm.precision_score(y,pred)\n",
        "  re = sm.recall_score(y,pred)\n",
        "  f1 = sm.f1_score(pred, y, average='macro')\n",
        "  return acc,pr,re,f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEvzyPl9NJsE",
        "outputId": "4edd2c77-faa6-4c6f-f17e-0aff4ab41ca8"
      },
      "source": [
        "acc_nb,pr_nb,re_nb,f1_nb=evaluate_model(predicted_classes,y_test)\n",
        "print(\"Accuracy : \"+str(acc_nb))\n",
        "print(\"Precision : \"+str(pr_nb))\n",
        "print(\"Recall : \"+str(re_nb))\n",
        "print(\"F1 Score : \"+str(f1_nb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.64\n",
            "Precision : 0.5933333333333334\n",
            "Recall : 0.6544117647058824\n",
            "F1 Score : 0.6392142888958177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8HHTO6EytW4"
      },
      "source": [
        "The metrics values are less as compared to the one trained using IMDB dataset. One reason is the size of the dataset. For LSTMs to perform well, input data should be of a fairly larger size than the one used in this model. Removing some irreleant stop words may improve the model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjZGbz7LOUxg"
      },
      "source": [
        "# **Question 6) (30 points)**\n",
        "\n",
        "Use the train.txt file from the PubMed 20K RCT dataset fine-tune a\n",
        "BERT transformer (class 9 code). This task is a bit different as the one seen in class, here the\n",
        "source dataset has FIVE different classes: background, objective, method, result, and\n",
        "conclusion. Once the BERT model is fine-tuned, classify the: test.txt set. Please present the\n",
        "per-class classification report (accuracy, precision, recall, f1-score metrics). Also, present the\n",
        "global metrics - all classes (accuracy, precision, recall, f1-score metrics). Did you model beat the\n",
        "baseline results (https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve\n",
        "it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW4n2EOSOctt"
      },
      "source": [
        "q6_data = pd.read_csv('/content/drive/MyDrive/exam2/train.txt',delimiter= '\\t',skipinitialspace=True, header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMIRH5rrnk-A"
      },
      "source": [
        "q6_test = pd.read_csv('/content/drive/MyDrive/exam2/test.txt',delimiter= '\\t',skipinitialspace=True, header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "I9hG1l8invPB",
        "outputId": "0038c9c2-3251-44af-e5a4-a1dc64f11c54"
      },
      "source": [
        "q6_test.columns=['label','text']\n",
        "q6_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>This study analyzed liver function abnormaliti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>A post hoc analysis was conducted with the use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Liver function tests ( LFTs ) were measured at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>Survival analyses were used to assess the asso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>The percentage of patients with abnormal LFTs ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        label                                               text\n",
              "0  BACKGROUND  This study analyzed liver function abnormaliti...\n",
              "1     RESULTS  A post hoc analysis was conducted with the use...\n",
              "2     RESULTS  Liver function tests ( LFTs ) were measured at...\n",
              "3     RESULTS  Survival analyses were used to assess the asso...\n",
              "4     RESULTS  The percentage of patients with abnormal LFTs ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqVITi4lRQ0j"
      },
      "source": [
        "q6_data.columns=['label','text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "OpOn7sLmfUaA",
        "outputId": "31ebcc09-ca8b-4d9f-f444-841390cfcce7"
      },
      "source": [
        "q6_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>To investigate the efficacy of 6 weeks of dail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>A total of 125 patients with primary knee OA w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Outcome measures included pain reduction and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Pain was assessed using the visual analog pain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>Secondary outcome measures included the Wester...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                               text\n",
              "0  OBJECTIVE  To investigate the efficacy of 6 weeks of dail...\n",
              "1    METHODS  A total of 125 patients with primary knee OA w...\n",
              "2    METHODS  Outcome measures included pain reduction and i...\n",
              "3    METHODS  Pain was assessed using the visual analog pain...\n",
              "4    METHODS  Secondary outcome measures included the Wester..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL-N05_3eZkP"
      },
      "source": [
        "q6_classes=['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS']\n",
        "q6_data['label'] = q6_data['label'].map({'BACKGROUND':0, 'OBJECTIVE':1, 'METHODS':2, 'RESULTS':3, 'CONCLUSIONS':4}).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KG6Zi16n92b"
      },
      "source": [
        "q6_test['label'] = q6_test['label'].map({'BACKGROUND':0, 'OBJECTIVE':1, 'METHODS':2, 'RESULTS':3, 'CONCLUSIONS':4}).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "7uyqqzmeegvM",
        "outputId": "9d830499-2948-4d5a-a924-33a86da5d9c2"
      },
      "source": [
        "q6_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>To investigate the efficacy of 6 weeks of dail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>A total of 125 patients with primary knee OA w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Outcome measures included pain reduction and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Pain was assessed using the visual analog pain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Secondary outcome measures included the Wester...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      1  To investigate the efficacy of 6 weeks of dail...\n",
              "1      2  A total of 125 patients with primary knee OA w...\n",
              "2      2  Outcome measures included pain reduction and i...\n",
              "3      2  Pain was assessed using the visual analog pain...\n",
              "4      2  Secondary outcome measures included the Wester..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "4kRmMMdboDg0",
        "outputId": "125d55ce-4fe8-4a1d-f8e1-aaedcef24a01"
      },
      "source": [
        "q6_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>This study analyzed liver function abnormaliti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>A post hoc analysis was conducted with the use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Liver function tests ( LFTs ) were measured at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Survival analyses were used to assess the asso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>The percentage of patients with abnormal LFTs ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30130</th>\n",
              "      <td>3</td>\n",
              "      <td>There was a statistically significant between-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30131</th>\n",
              "      <td>3</td>\n",
              "      <td>There were no statistically significant betwee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30132</th>\n",
              "      <td>3</td>\n",
              "      <td>There was no significant association between s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30133</th>\n",
              "      <td>3</td>\n",
              "      <td>No adverse effects were reported .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30134</th>\n",
              "      <td>4</td>\n",
              "      <td>Performing a 6-week do-as-tolerated program of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30135 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                               text\n",
              "0          0  This study analyzed liver function abnormaliti...\n",
              "1          3  A post hoc analysis was conducted with the use...\n",
              "2          3  Liver function tests ( LFTs ) were measured at...\n",
              "3          3  Survival analyses were used to assess the asso...\n",
              "4          3  The percentage of patients with abnormal LFTs ...\n",
              "...      ...                                                ...\n",
              "30130      3  There was a statistically significant between-...\n",
              "30131      3  There were no statistically significant betwee...\n",
              "30132      3  There was no significant association between s...\n",
              "30133      3                 No adverse effects were reported .\n",
              "30134      4  Performing a 6-week do-as-tolerated program of...\n",
              "\n",
              "[30135 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1khYN_gUnL0",
        "outputId": "645c326b-3618-4f2b-8cad-1b5bf2c1a385"
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    print('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh1aF8O4Xfzl",
        "outputId": "eac11e45-4f90-4de4-9985-07e3c61d79d7"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXRE7pyvYKM1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttHw-wpHYPJF"
      },
      "source": [
        "q6_text = q6_data.iloc[:,1].values\n",
        "q6_label = q6_data.iloc[:,0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIZ3k4n2utFR"
      },
      "source": [
        "# q6_test.iloc[:,0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPG3Cf2ztEIr"
      },
      "source": [
        "q6_text_test = q6_test.iloc[:,1].values\n",
        "q6_label_test = q6_test.iloc[:,0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpUsF5jRZkxb"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO09LfciaF33",
        "outputId": "0e250ef8-a884-4954-df6e-a754956b491d"
      },
      "source": [
        "print(' Original: ', q6_text[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(q6_text[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(q6_text[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Tokenized:  ['to', 'investigate', 'the', 'efficacy', 'of', '6', 'weeks', 'of', 'daily', 'low', '-', 'dose', 'oral', 'pre', '##d', '##nis', '##olo', '##ne', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low', '-', 'grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '12', 'weeks', 'in', 'older', 'adults', 'with', 'moderate', 'to', 'severe', 'knee', 'os', '##te', '##oa', '##rth', '##rit', '##is', '(', 'o', '##a', ')', '.']\n",
            "Token IDs:  [2000, 8556, 1996, 21150, 1997, 1020, 3134, 1997, 3679, 2659, 1011, 13004, 8700, 3653, 2094, 8977, 12898, 2638, 1999, 9229, 3255, 1010, 12969, 1010, 1998, 22575, 2659, 1011, 3694, 21733, 1999, 1996, 2460, 2744, 1998, 3251, 1996, 3466, 2052, 2022, 8760, 2012, 2260, 3134, 1999, 3080, 6001, 2007, 8777, 2000, 5729, 6181, 9808, 2618, 10441, 15265, 14778, 2483, 1006, 1051, 2050, 1007, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7yQ59aDcck9"
      },
      "source": [
        "def bert_encode(data_bert,l):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in data_bert:\n",
        "      encoded_dict = tokenizer.encode_plus(sent, add_special_tokens = True, max_length = 64,pad_to_max_length = True,return_attention_mask = True,return_tensors = 'pt') \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  l = torch.tensor(l)\n",
        "  return input_ids,attention_masks,l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKymfstgth8f",
        "outputId": "68e3359d-978c-4652-ecb4-10284e70c75c"
      },
      "source": [
        "input_ids_train,attention_masks_train,l_train = bert_encode(q6_text,q6_label)\n",
        "input_ids_test,attention_masks_test,l_test = bert_encode(q6_text_test,q6_label_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_4hXbPkiACj",
        "outputId": "af3821f2-4a0f-46d7-d1d7-4e13c029149a"
      },
      "source": [
        "print('Original: ', q6_text[0])\n",
        "print('Token IDs:', input_ids_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Token IDs: tensor([  101,  2000,  8556,  1996, 21150,  1997,  1020,  3134,  1997,  3679,\n",
            "         2659,  1011, 13004,  8700,  3653,  2094,  8977, 12898,  2638,  1999,\n",
            "         9229,  3255,  1010, 12969,  1010,  1998, 22575,  2659,  1011,  3694,\n",
            "        21733,  1999,  1996,  2460,  2744,  1998,  3251,  1996,  3466,  2052,\n",
            "         2022,  8760,  2012,  2260,  3134,  1999,  3080,  6001,  2007,  8777,\n",
            "         2000,  5729,  6181,  9808,  2618, 10441, 15265, 14778,  2483,  1006,\n",
            "         1051,  2050,  1007,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AEJUabXiTlY",
        "outputId": "40ff586a-afab-4187-8442-094ef7bb534a"
      },
      "source": [
        "q6_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1ktmwn7v7Tk",
        "outputId": "5fd61168-6992-4b2b-87ca-f7be876b5bb0"
      },
      "source": [
        "q6_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30135, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzZ1v6jakH5y",
        "outputId": "12122ee7-f1d6-47c9-df47-e002d9f91a2c"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, l_train)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset_train))\n",
        "val_size = len(dataset_train) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset_train, [train_size, val_size],generator=torch.Generator().manual_seed(seed_value))\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "dataset_test = TensorDataset(input_ids_test, attention_masks_test, l_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162,036 training samples\n",
            "18,004 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N3vgMMZd1PP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = 32 # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = 32 # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hviww7TFv1uD",
        "outputId": "3e679eb2-2575-426a-a14f-d84b50fdb1a3"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels = 5,output_attentions = False,output_hidden_states = False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kSayCcswvxQ"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onNRkdVyxOsK"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 2\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0,num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67wtTQdKxnfL"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gICY9Do0xyFN"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgyo5N72z0x1"
      },
      "source": [
        "# import torch\n",
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-5ExD0Lx4Nl",
        "outputId": "492fb66b-ebcf-4d05-9f6f-b2116a61f257"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        " \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        " \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "   \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "     \n",
        "        model.zero_grad()        \n",
        "\n",
        "     \n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "       \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "   \n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "  \n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "    \n",
        "        with torch.no_grad():        \n",
        "\n",
        "        \n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "      \n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      \n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:15.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:31.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:47.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:01:02.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:18.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:33.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:49.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:02:05.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:20.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:36.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:51.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:03:07.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:23.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:38.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:54.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:04:10.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:25.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:41.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:56.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:05:12.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:28.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:43.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:59.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:06:14.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:30.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:45.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:07:01.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:07:17.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:07:32.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:48.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:08:03.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:08:19.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:08:35.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:50.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:09:06.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:09:22.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:09:37.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:53.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:10:08.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:10:24.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:10:40.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:55.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:11:11.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:11:26.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:11:42.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:58.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:12:13.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:12:29.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:12:44.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:13:00.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:13:15.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:13:31.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:13:47.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:14:02.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:14:18.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:14:33.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:14:49.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:15:05.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:15:20.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:15:36.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:15:51.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:16:07.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:16:23.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:16:38.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:16:54.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:17:09.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:17:25.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:17:41.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:17:56.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:18:12.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:18:27.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:18:43.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:18:59.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:19:14.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:19:30.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:19:45.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:20:01.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:20:16.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:20:32.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:20:48.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:21:03.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:21:19.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:21:35.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:21:50.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:22:06.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:22:21.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:22:37.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:22:53.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:23:08.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:23:24.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:23:39.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:23:55.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:24:10.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:24:26.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:24:42.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:24:57.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:25:13.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:25:28.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:25:44.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:26:00.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:26:15.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:26:31.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:26:46.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:27:02.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:27:17.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:27:33.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:27:49.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:28:04.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:28:20.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:28:35.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:28:51.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:29:06.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:29:22.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:29:38.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:29:53.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:30:09.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:30:25.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:30:40.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:30:56.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:31:11.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:31:27.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:31:42.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:31:58.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:32:14.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:32:29.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:32:45.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:32:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.36\n",
            "  Validation took: 0:01:15\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:31.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:47.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:01:02.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:18.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:33.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:49.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:02:05.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:20.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:36.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:52.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:03:07.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:23.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:38.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:54.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:04:09.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:25.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:41.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:56.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:05:12.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:27.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:43.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:59.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:06:14.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:30.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:46.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:07:01.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:07:17.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:07:32.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:48.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:08:03.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:08:19.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:08:35.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:50.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:09:06.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:09:21.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:09:37.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:53.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:10:08.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:10:24.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:10:39.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:55.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:11:10.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:11:26.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:11:42.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:57.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:12:13.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:12:29.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:12:44.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:13:00.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:13:15.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:13:31.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:13:46.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:14:02.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:14:18.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:14:33.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:14:49.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:15:04.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:15:20.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:15:36.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:15:51.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:16:07.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:16:22.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:16:38.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:16:54.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:17:09.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:17:25.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:17:40.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:17:56.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:18:12.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:18:27.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:18:43.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:18:58.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:19:14.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:19:30.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:19:45.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:20:01.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:20:16.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:20:32.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:20:47.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:21:03.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:21:19.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:21:34.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:21:50.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:22:06.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:22:21.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:22:37.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:22:52.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:23:08.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:23:24.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:23:39.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:23:55.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:24:10.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:24:26.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:24:42.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:24:57.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:25:13.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:25:29.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:25:44.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:26:00.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:26:15.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:26:31.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:26:47.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:27:02.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:27:18.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:27:33.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:27:49.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:28:05.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:28:20.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:28:36.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:28:51.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:29:07.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:29:23.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:29:38.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:29:54.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:30:09.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:30:25.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:30:41.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:30:56.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:31:12.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:31:28.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:31:43.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:31:59.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:32:14.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:32:30.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:32:46.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:32:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.35\n",
            "  Validation took: 0:01:16\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:08:20 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "WeSNqE7uJ72O",
        "outputId": "b9d1ce80-6ccc-4865-972d-fd96663b4315"
      },
      "source": [
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:32:54</td>\n",
              "      <td>0:01:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0:32:55</td>\n",
              "      <td>0:01:16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.41         0.36           0.87       0:32:54         0:01:15\n",
              "2               0.31         0.35           0.88       0:32:55         0:01:16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "Rzhz31YWKvUS",
        "outputId": "a4041be9-c88b-4bd1-a586-774de477e6b5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skan6pyINnaW"
      },
      "source": [
        "# Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UouJWC80NZ73"
      },
      "source": [
        "# Create the DataLoader.\n",
        "prediction_sampler = SequentialSampler(dataset_test)\n",
        "prediction_dataloader = DataLoader(dataset_test, sampler=prediction_sampler, batch_size=29)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGWV5-uqQ9Tj",
        "outputId": "9eb2815d-b927-4809-8ddf-b57721bdb2f8"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 30,135 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4cVa8BdS1ej"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvV5DDNG_BYS",
        "outputId": "ac429bfa-a6c2-46eb-9af2-098d657251e5"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "metrics_report = classification_report(flat_true_labels, flat_predictions,target_names=['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS'])\n",
        "\n",
        "print(metrics_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.68      0.81      0.74      3621\n",
            "   OBJECTIVE       0.77      0.55      0.64      2333\n",
            "     METHODS       0.93      0.95      0.94      9897\n",
            "     RESULTS       0.93      0.91      0.92      9713\n",
            " CONCLUSIONS       0.85      0.82      0.83      4571\n",
            "\n",
            "    accuracy                           0.87     30135\n",
            "   macro avg       0.83      0.81      0.82     30135\n",
            "weighted avg       0.87      0.87      0.87     30135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbbNNmoEAiZv"
      },
      "source": [
        "import sklearn.metrics as sm\n",
        "def evaluate_model_bert(pred,y):\n",
        "  acc = sm.accuracy_score(y,pred)\n",
        "  pr = sm.precision_score(y,pred, average='macro')\n",
        "  re = sm.recall_score(y,pred, average='macro')\n",
        "  f1 = sm.f1_score(pred, y, average='macro')\n",
        "  return acc,pr,re,f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmXfjN9Q_ySS",
        "outputId": "165843fd-2a97-4158-d79d-69b193ad4cbb"
      },
      "source": [
        "acc_bert,pr_bert,re_bert,f1_bert=evaluate_model_bert(flat_predictions,flat_true_labels)\n",
        "print(\"Accuracy : \"+str(acc_bert))\n",
        "print(\"Precision : \"+str(pr_bert))\n",
        "print(\"Recall : \"+str(re_bert))\n",
        "print(\"F1 Score : \"+str(f1_bert))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8710137713622034\n",
            "Precision : 0.830231850480325\n",
            "Recall : 0.8095318881412659\n",
            "F1 Score : 0.8151079578451069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH1lHQL44U62"
      },
      "source": [
        "The model has ***not beaten*** the the baseline models however has performed fairly decent in terms of its scores.\n",
        "Model will improve if the embedding layer is used such that it is trained in regard to the kind of dataset it is supposed to be used for rather than any generic embedding. Generic BERT is not trained on specific datasets suited for specific purposes so something like blueBert or bioBert helps better train datasets like the one presented for this question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyR1i-qr3iEW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stJDQCDNb9H9"
      },
      "source": [
        "# **Bonus Question: (50 points)** \n",
        "\n",
        "Solve question 6 but instead for fine-tuning BERT, use: BioBert\n",
        "(20 points) and BlueBERT (20 points) and compare the results of the three approaches in a\n",
        "nice table. Answer the following questions: Did you model beat the baseline results\n",
        "(https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e1sFGeifN83"
      },
      "source": [
        "!pip install biobert_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgnP06stfKPl"
      },
      "source": [
        "from biobert_embedding.embedding import BiobertEmbedding\n",
        "import biobert_embedding "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7bTFFrvf8HN",
        "outputId": "cb18465d-de14-4a1a-c5d9-8fb9fad40dbb"
      },
      "source": [
        "path = biobert_embedding.downloader.get_BioBert(\"google drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading the biobert model, will take a minute...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFfoW2aIkIY4"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(path, do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2E_MPuSiq1q"
      },
      "source": [
        "def bert_encode(data_bert,l):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in data_bert:\n",
        "      encoded_dict = tokenizer.encode_plus(sent, add_special_tokens = True, max_length = 64,pad_to_max_length = True,return_attention_mask = True,return_tensors = 'pt') \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  l = torch.tensor(l)\n",
        "  return input_ids,attention_masks,l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeNDpSN_iq1q",
        "outputId": "e6ad9f16-a7c6-4adb-8ba0-b0678873aad5"
      },
      "source": [
        "input_ids_train_bio,attention_masks_train_bio,l_train_bio = bert_encode(q6_text,q6_label)\n",
        "input_ids_test_bio,attention_masks_test_bio,l_test_bio = bert_encode(q6_text_test,q6_label_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZqe-jn1iq1r",
        "outputId": "ebf7bfe3-de64-4498-a7ad-3223103afe5b"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset_train = TensorDataset(input_ids_train_bio, attention_masks_train_bio, l_train_bio)\n",
        "\n",
        "\n",
        "train_size = int(0.9 * len(dataset_train))\n",
        "val_size = len(dataset_train) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset_train, [train_size, val_size],generator=torch.Generator().manual_seed(seed_value))\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "dataset_test = TensorDataset(input_ids_test_bio, attention_masks_test_bio, l_test_bio)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162,036 training samples\n",
            "18,004 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enw4HDbciq1r"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = 32 # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = 32 # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Xoo4Piiq1r",
        "outputId": "55729d00-ccf9-40d3-e147-ab49a302525c"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(path,num_labels = 5,output_attentions = False,output_hidden_states = False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/biobert_v1.1_pubmed_pytorch_model were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/biobert_v1.1_pubmed_pytorch_model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ0llYKGiq1t"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbEe_7HQiq1t"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 2\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0,num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkJmaqrQiq1t",
        "outputId": "672fe863-e0e3-4060-9b3e-d8ce510c8744"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        " \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "       \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        " \n",
        "        with torch.no_grad():        \n",
        "\n",
        "        \n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "      \n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "       \n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:56.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:01:23.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:01:51.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:02:19.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:02:47.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:03:14.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:03:42.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:04:10.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:04:38.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:05:05.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:05:33.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:06:01.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:06:28.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:06:56.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:07:24.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:07:52.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:08:19.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:08:47.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:09:15.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:09:43.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:10:10.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:10:38.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:11:06.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:11:33.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:12:01.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:12:29.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:12:56.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:13:24.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:13:52.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:14:20.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:14:47.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:15:15.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:15:43.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:16:10.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:16:38.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:17:06.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:17:33.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:18:01.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:18:29.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:18:57.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:19:24.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:19:52.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:20:20.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:20:47.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:21:15.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:21:43.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:22:11.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:22:38.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:23:06.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:23:34.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:24:01.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:24:29.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:24:57.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:25:24.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:25:52.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:26:20.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:26:47.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:27:15.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:27:43.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:28:11.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:28:38.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:29:06.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:29:34.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:30:02.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:30:29.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:30:57.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:31:25.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:31:53.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:32:20.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:32:48.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:33:16.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:33:43.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:34:11.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:34:39.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:35:06.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:35:34.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:36:02.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:36:30.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:36:57.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:37:25.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:37:53.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:38:20.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:38:48.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:39:16.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:39:43.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:40:11.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:40:39.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:41:06.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:41:34.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:42:02.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:42:30.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:42:57.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:43:25.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:43:53.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:44:20.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:44:48.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:45:16.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:45:43.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:46:11.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:46:39.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:47:07.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:47:34.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:48:02.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:48:30.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:48:57.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:49:25.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:49:53.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:50:20.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:50:48.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:51:16.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:51:44.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:52:11.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:52:39.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:53:07.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:53:35.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:54:02.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:54:30.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:54:58.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:55:25.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:55:53.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:56:21.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:56:49.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:57:16.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:57:44.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:58:12.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:58:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:02:08\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:28.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:55.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:01:23.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:01:51.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:02:19.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:02:46.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:03:14.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:03:42.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:04:09.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:04:37.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:05:05.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:05:33.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:06:01.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:06:28.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:06:56.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:07:24.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:07:51.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:08:19.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:08:47.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:09:15.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:09:42.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:10:10.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:10:38.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:11:05.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:11:33.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:12:01.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:12:28.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:12:56.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:13:24.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:13:52.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:14:19.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:14:47.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:15:15.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:15:42.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:16:10.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:16:38.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:17:06.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:17:33.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:18:01.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:18:29.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:18:56.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:19:24.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:19:52.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:20:20.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:20:47.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:21:15.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:21:43.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:22:11.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:22:38.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:23:06.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:23:34.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:24:02.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:24:29.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:24:57.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:25:25.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:25:52.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:26:20.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:26:48.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:27:16.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:27:44.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:28:11.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:28:39.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:29:07.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:29:35.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:30:02.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:30:30.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:30:58.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:31:25.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:31:53.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:32:21.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:32:49.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:33:16.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:33:44.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:34:12.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:34:39.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:35:07.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:35:35.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:36:03.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:36:30.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:36:58.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:37:26.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:37:54.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:38:21.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:38:49.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:39:17.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:39:44.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:40:12.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:40:40.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:41:08.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:41:36.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:42:03.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:42:31.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:42:59.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:43:27.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:43:54.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:44:22.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:44:50.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:45:18.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:45:45.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:46:13.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:46:41.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:47:08.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:47:36.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:48:04.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:48:32.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:48:59.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:49:27.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:49:55.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:50:23.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:50:50.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:51:18.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:51:46.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:52:14.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:52:41.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:53:09.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:53:37.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:54:05.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:54:32.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:55:00.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:55:28.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:55:56.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:56:23.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:56:51.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:57:19.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:57:46.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:58:14.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:58:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.33\n",
            "  Validation took: 0:02:08\n",
            "\n",
            "Training complete!\n",
            "Total training took 2:01:16 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "OYSpnS5P-bAz",
        "outputId": "574c8fdd-9252-4213-8f0b-0c3f41e3bb99"
      },
      "source": [
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.37</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0:58:28</td>\n",
              "      <td>0:02:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0:58:31</td>\n",
              "      <td>0:02:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.37         0.33           0.88       0:58:28         0:02:08\n",
              "2               0.27         0.33           0.88       0:58:31         0:02:08"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "osXt4fHB-bA4",
        "outputId": "87f494b0-e608-4714-cdd4-d3b00d2e68b6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8_6nNw9-bA5"
      },
      "source": [
        "# Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIP3fFVT-bA7"
      },
      "source": [
        "# Create the DataLoader.\n",
        "prediction_sampler = SequentialSampler(dataset_test)\n",
        "prediction_dataloader = DataLoader(dataset_test, sampler=prediction_sampler, batch_size=29)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7uptU45-bA8",
        "outputId": "0eb655d2-af89-498e-866c-a4b4154eab12"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test_bio)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  \n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 30,135 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVwEYpn4-bA9"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDY_1uk0-bA9",
        "outputId": "c8b9acb6-010a-43e3-c639-ce5dbc03ea54"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "metrics_report = classification_report(flat_true_labels, flat_predictions,target_names=['BACKGROUND', 'OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS'])\n",
        "\n",
        "print(metrics_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.69      0.82      0.75      3621\n",
            "   OBJECTIVE       0.77      0.57      0.65      2333\n",
            "     METHODS       0.93      0.96      0.94      9897\n",
            "     RESULTS       0.93      0.92      0.92      9713\n",
            " CONCLUSIONS       0.87      0.84      0.85      4571\n",
            "\n",
            "    accuracy                           0.88     30135\n",
            "   macro avg       0.84      0.82      0.82     30135\n",
            "weighted avg       0.88      0.88      0.88     30135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkH9wC2U-bBB",
        "outputId": "0c687bbc-5bb7-423d-a749-b6594165afc1"
      },
      "source": [
        "acc_bertbio,pr_bertbio,re_bertbio,f1_bertbio=evaluate_model_bert(flat_predictions,flat_true_labels)\n",
        "print(\"Accuracy : \"+str(acc_bertbio))\n",
        "print(\"Precision : \"+str(pr_bertbio))\n",
        "print(\"Recall : \"+str(re_bertbio))\n",
        "print(\"F1 Score : \"+str(f1_bertbio))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8791770366683259\n",
            "Precision : 0.8383543945999843\n",
            "Recall : 0.8192483188370876\n",
            "F1 Score : 0.8247273690979648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCoXma0GDySO"
      },
      "source": [
        "mt_df = pd.DataFrame()\n",
        "mt_df = mt_df.append({'accuracy':acc_bert,'precision':pr_bert,'recall':re_bert,'f1 score':f1_bert},ignore_index=True)\n",
        "mt_df = mt_df.append({'accuracy':acc_bertbio,'precision':pr_bertbio,'recall':re_bertbio,'f1 score':f1_bertbio},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uMfnOb9FeX7"
      },
      "source": [
        "mt_df.index =['bert','bioBert']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "AGNUd5VYFzpD",
        "outputId": "1c2f49b3-43db-42ca-e0b9-a315a3122f8e"
      },
      "source": [
        "mt_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1 score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bert</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bioBert</th>\n",
              "      <td>0.88</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         accuracy  f1 score  precision  recall\n",
              "bert         0.87      0.82       0.83    0.81\n",
              "bioBert      0.88      0.82       0.84    0.82"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqgZBwuZGJ-y"
      },
      "source": [
        "Based on the above table, values suggest that biobert has surpassed generic bert in modeling the given dataset. Time did not permit to proceed for blueBert"
      ]
    }
  ]
}