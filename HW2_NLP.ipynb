{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJtXJlLYK3p1Xla8oedV7E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varchala/NaturalLanguageProcessing_CSC8980/blob/main/HW2_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eIBEInjgRbF"
      },
      "source": [
        "**Varchaleswari Ganugapati**\r\n",
        "\r\n",
        "**vganugapati1@student.gsu.edu**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt_0hwT2gflj"
      },
      "source": [
        "**1.** Create a cosine similarity matrix for all of Shakespeare’s works found in the provided\r\n",
        "file. This will result in a 42 by 42 matrix with the cosine similarity between each of his\r\n",
        "works. In other words, calculate the document-wise cosine similarity between all of\r\n",
        "Shakepeare’s works. (50 points). Use TF_IDF for this. Note, you can use the Cosine\r\n",
        "Similarity function on scikit-learn or implement your own, but no other library/package is\r\n",
        "allowed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYhDOulGgDmm"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import os"
      ],
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78mBxIS2pcXV",
        "outputId": "a1812331-027c-4b27-9874-21dce4500d9a"
      },
      "source": [
        "#Data preprocessing\r\n",
        "path='/content/sample_data/shakp'\r\n",
        "count=0\r\n",
        "fileMatrix=[]\r\n",
        "fileName=[]\r\n",
        "with os.scandir(path) as files:\r\n",
        "    for file in files:\r\n",
        "        if file.name.endswith(\".txt\"):\r\n",
        "            count +=1\r\n",
        "            fileName.append(file.name)\r\n",
        "            with open(path+\"/\"+file.name) as openfile:\r\n",
        "              fileMatrix.append(openfile.read())\r\n",
        "    print(count)"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMiYUq53x1hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9dd502b-f12f-4374-c071-852cf721b0f1"
      },
      "source": [
        "# print(fileMatrix[1])\r\n",
        "print(fileName)"
      ],
      "execution_count": 460,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the-two-noble-kinsmen_TXT_FolgerShakespeare.txt', 'coriolanus_TXT_FolgerShakespeare.txt', 'henry-iv-part-1_TXT_FolgerShakespeare.txt', 'king-john_TXT_FolgerShakespeare.txt', 'king-lear_TXT_FolgerShakespeare.txt', 'henry-v_TXT_FolgerShakespeare.txt', 'henry-vi-part-1_TXT_FolgerShakespeare.txt', 'a-midsummer-nights-dream_TXT_FolgerShakespeare.txt', 'pericles_TXT_FolgerShakespeare.txt', 'the-comedy-of-errors_TXT_FolgerShakespeare.txt', 'othello_TXT_FolgerShakespeare.txt', 'the-merry-wives-of-windsor_TXT_FolgerShakespeare.txt', 'venus-and-adonis_TXT_FolgerShakespeare.txt', 'the-phoenix-and-turtle_TXT_FolgerShakespeare.txt', 'troilus-and-cressida_TXT_FolgerShakespeare.txt', 'the-merchant-of-venice_TXT_FolgerShakespeare.txt', 'henry-iv-part-2_TXT_FolgerShakespeare.txt', 'alls-well-that-ends-well_TXT_FolgerShakespeare.txt', 'shakespeares-sonnets_TXT_FolgerShakespeare.txt', 'antony-and-cleopatra_TXT_FolgerShakespeare.txt', 'the-winters-tale_TXT_FolgerShakespeare.txt', 'measure-for-measure_TXT_FolgerShakespeare.txt', 'titus-andronicus_TXT_FolgerShakespeare.txt', 'twelfth-night_TXT_FolgerShakespeare.txt', 'henry-vi-part-2_TXT_FolgerShakespeare.txt', 'the-two-gentlemen-of-verona_TXT_FolgerShakespeare.txt', 'macbeth_TXT_FolgerShakespeare.txt', 'much-ado-about-nothing_TXT_FolgerShakespeare.txt', 'cymbeline_TXT_FolgerShakespeare.txt', 'the-tempest_TXT_FolgerShakespeare.txt', 'the-taming-of-the-shrew_TXT_FolgerShakespeare.txt', 'hamlet_TXT_FolgerShakespeare.txt', 'lucrece_TXT_FolgerShakespeare.txt', 'as-you-like-it_TXT_FolgerShakespeare.txt', 'timon-of-athens_TXT_FolgerShakespeare.txt', 'richard-ii_TXT_FolgerShakespeare.txt', 'richard-iii_TXT_FolgerShakespeare.txt', 'romeo-and-juliet_TXT_FolgerShakespeare.txt', 'henry-vi-part-3_TXT_FolgerShakespeare.txt', 'julius-caesar_TXT_FolgerShakespeare.txt', 'loves-labors-lost_TXT_FolgerShakespeare.txt', 'henry-viii_TXT_FolgerShakespeare.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK9m-m49pVvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836d259c-1911-40d9-96f2-1266326393d7"
      },
      "source": [
        "\r\n",
        "\r\n",
        "#TfidfVectorizer object\r\n",
        "vectorizer = TfidfVectorizer()\r\n",
        "\r\n",
        "# matrix of word vectors\r\n",
        "tfidf_matrix = vectorizer.fit_transform(fileMatrix)\r\n",
        "\r\n",
        "#shape of tfidf_matrix\r\n",
        "print(tfidf_matrix.shape)"
      ],
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42, 24618)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEG4vLGGEZ9O"
      },
      "source": [
        ""
      ],
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1lDQkW_3pDr",
        "outputId": "6021fa50-04b8-463a-e588-8bd71e73f256"
      },
      "source": [
        "tfidf_tokens = vectorizer.get_feature_names()\r\n",
        "print(tfidf_tokens[20:40])\r\n",
        "print(len(tfidf_tokens))"
      ],
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135']\n",
            "24618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzAVwji8pKzm"
      },
      "source": [
        "\r\n",
        "# compute and print the cosine similarity matrix\r\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\r\n"
      ],
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBihWmFK20xH",
        "outputId": "223b179b-504a-4b47-85ea-3eb815d46f19"
      },
      "source": [
        "print(cosine_sim.shape)\r\n",
        "print(cosine_sim)"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42, 42)\n",
            "[[1.         0.59813572 0.65459176 ... 0.52515851 0.57395169 0.69694474]\n",
            " [0.59813572 1.         0.66801609 ... 0.5890345  0.59258345 0.71771293]\n",
            " [0.65459176 0.66801609 1.         ... 0.59895863 0.66716633 0.79038899]\n",
            " ...\n",
            " [0.52515851 0.5890345  0.59895863 ... 1.         0.52277672 0.62033426]\n",
            " [0.57395169 0.59258345 0.66716633 ... 0.52277672 1.         0.70530628]\n",
            " [0.69694474 0.71771293 0.79038899 ... 0.62033426 0.70530628 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQCf9VHk1qmW"
      },
      "source": [
        "**2.** Write a function that takes the previous matrix and a number n as parameters (nothing\r\n",
        "else will be accepted) and return the top n similar works. Use the function to output the\r\n",
        "top 10 similar works. (30 points).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_W__PhfpKgo"
      },
      "source": [
        "# df = pd.DataFrame(cosine_sim,columns=fileName,index=fileName)\r\n",
        "# df.stack().nlargest(20)"
      ],
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UZSDe9P5qWn",
        "outputId": "689f8ba1-07ae-4e66-b938-a03f7db4e7e3"
      },
      "source": [
        "def find_similar_docs(matrix,n):\r\n",
        "  docs=[]\r\n",
        "  np.fill_diagonal(matrix, 0)\r\n",
        "  idx = np.argsort(matrix.ravel())[:-n-1:-1]\r\n",
        "  similar = np.column_stack(np.unravel_index(idx, matrix.shape))\r\n",
        "  for i in range(n):\r\n",
        "    docs.append(fileName[similar[i][0]])\r\n",
        "  return docs\r\n",
        "out = find_similar_docs(cosine_sim,10)\r\n",
        "print(out)\r\n",
        "print(\"The list is:\")\r\n",
        "for i in out:\r\n",
        "  print(i)"
      ],
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['venus-and-adonis_TXT_FolgerShakespeare.txt', 'lucrece_TXT_FolgerShakespeare.txt', 'henry-iv-part-2_TXT_FolgerShakespeare.txt', 'henry-iv-part-1_TXT_FolgerShakespeare.txt', 'shakespeares-sonnets_TXT_FolgerShakespeare.txt', 'lucrece_TXT_FolgerShakespeare.txt', 'henry-vi-part-2_TXT_FolgerShakespeare.txt', 'henry-vi-part-1_TXT_FolgerShakespeare.txt', 'richard-ii_TXT_FolgerShakespeare.txt', 'richard-iii_TXT_FolgerShakespeare.txt']\n",
            "The list is:\n",
            "venus-and-adonis_TXT_FolgerShakespeare.txt\n",
            "lucrece_TXT_FolgerShakespeare.txt\n",
            "henry-iv-part-2_TXT_FolgerShakespeare.txt\n",
            "henry-iv-part-1_TXT_FolgerShakespeare.txt\n",
            "shakespeares-sonnets_TXT_FolgerShakespeare.txt\n",
            "lucrece_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-2_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-1_TXT_FolgerShakespeare.txt\n",
            "richard-ii_TXT_FolgerShakespeare.txt\n",
            "richard-iii_TXT_FolgerShakespeare.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yzrRN8WLXLx"
      },
      "source": [
        "**As the similarity is between pairs of docs, I wrote one more function  that returns the top k \"pairs\" of docs rather than just the docs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psm6FDlkLVdL",
        "outputId": "5aed6c3b-652a-48bf-972f-4d875318ba61"
      },
      "source": [
        "def find_similar_docs(matrix,n):\r\n",
        "  docs=[]\r\n",
        "  final_doc=[]\r\n",
        "  np.fill_diagonal(matrix, 0)\r\n",
        "  n=n*2\r\n",
        "  idx = np.argsort(matrix.ravel())[:-n-1:-1]\r\n",
        "  similar = np.column_stack(np.unravel_index(idx, matrix.shape))\r\n",
        "  for i in range(n):\r\n",
        "    docs.append(fileName[similar[i][0]])\r\n",
        "  for i in range(0,len(docs)-1,2):\r\n",
        "    final_doc.append(docs[i]+\" && \"+docs[i+1])\r\n",
        "  return final_doc\r\n",
        "out = find_similar_docs(cosine_sim,10)\r\n",
        "# print(out)\r\n",
        "print(\"The doc pairs are:\")\r\n",
        "for i in out:\r\n",
        "  print(i)"
      ],
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The doc pairs are:\n",
            "venus-and-adonis_TXT_FolgerShakespeare.txt && lucrece_TXT_FolgerShakespeare.txt\n",
            "henry-iv-part-2_TXT_FolgerShakespeare.txt && henry-iv-part-1_TXT_FolgerShakespeare.txt\n",
            "shakespeares-sonnets_TXT_FolgerShakespeare.txt && lucrece_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-2_TXT_FolgerShakespeare.txt && henry-vi-part-1_TXT_FolgerShakespeare.txt\n",
            "richard-ii_TXT_FolgerShakespeare.txt && richard-iii_TXT_FolgerShakespeare.txt\n",
            "venus-and-adonis_TXT_FolgerShakespeare.txt && shakespeares-sonnets_TXT_FolgerShakespeare.txt\n",
            "henry-viii_TXT_FolgerShakespeare.txt && henry-v_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-3_TXT_FolgerShakespeare.txt && henry-vi-part-2_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-2_TXT_FolgerShakespeare.txt && richard-ii_TXT_FolgerShakespeare.txt\n",
            "king-john_TXT_FolgerShakespeare.txt && henry-v_TXT_FolgerShakespeare.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c639eY1xOOsB"
      },
      "source": [
        "**The same code when the function prints the list values rather than returning them**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIWsRAQHOHMC",
        "outputId": "ccc45af2-65c8-4446-a9b4-96f26383707f"
      },
      "source": [
        "def find_similar_docs(matrix,n):\r\n",
        "  docs=[]\r\n",
        "  final_doc=[]\r\n",
        "  np.fill_diagonal(matrix, 0)\r\n",
        "  n=n*2\r\n",
        "  idx = np.argsort(matrix.ravel())[:-n-1:-1]\r\n",
        "  similar = np.column_stack(np.unravel_index(idx, matrix.shape))\r\n",
        "  for i in range(n):\r\n",
        "    docs.append(fileName[similar[i][0]])\r\n",
        "  for i in range(0,len(docs)-1,2):\r\n",
        "    final_doc.append(docs[i]+\" && \"+docs[i+1])\r\n",
        "  print(\"The list is:\")\r\n",
        "  for i in final_doc:\r\n",
        "    print(i)\r\n",
        "find_similar_docs(cosine_sim,10)\r\n",
        "# print(out)\r\n"
      ],
      "execution_count": 468,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The list is:\n",
            "venus-and-adonis_TXT_FolgerShakespeare.txt && lucrece_TXT_FolgerShakespeare.txt\n",
            "henry-iv-part-2_TXT_FolgerShakespeare.txt && henry-iv-part-1_TXT_FolgerShakespeare.txt\n",
            "shakespeares-sonnets_TXT_FolgerShakespeare.txt && lucrece_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-2_TXT_FolgerShakespeare.txt && henry-vi-part-1_TXT_FolgerShakespeare.txt\n",
            "richard-ii_TXT_FolgerShakespeare.txt && richard-iii_TXT_FolgerShakespeare.txt\n",
            "venus-and-adonis_TXT_FolgerShakespeare.txt && shakespeares-sonnets_TXT_FolgerShakespeare.txt\n",
            "henry-viii_TXT_FolgerShakespeare.txt && henry-v_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-3_TXT_FolgerShakespeare.txt && henry-vi-part-2_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-2_TXT_FolgerShakespeare.txt && richard-ii_TXT_FolgerShakespeare.txt\n",
            "king-john_TXT_FolgerShakespeare.txt && henry-v_TXT_FolgerShakespeare.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1N1hv51D9We"
      },
      "source": [
        "# # fileName[12 32]\r\n",
        "# out[5][0]"
      ],
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMZM8AE79VDJ"
      },
      "source": [
        "**3.** Using the code from the Language Models II class, train two simple language models\r\n",
        "using all of the files (together) in shakespeares-works_TXT_FolgerShakespeare.zip. One\r\n",
        "model should be trained using bigrams, the other using trigrams. (40 points).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5AVpkzCpbAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033adbc0-ca46-4ee1-e062-29dcb36d6f63"
      },
      "source": [
        "# Preprocess data\r\n",
        "import nltk, re\r\n",
        "from nltk import word_tokenize, sent_tokenize\r\n",
        "from nltk import bigrams, trigrams\r\n",
        "from collections import Counter, defaultdict\r\n",
        "nltk.download('punkt')\r\n",
        "import string"
      ],
      "execution_count": 470,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSFUyQilc_NF",
        "outputId": "98461cc3-741d-4609-b114-6d429f4949c3"
      },
      "source": [
        "print(len(fileMatrix))"
      ],
      "execution_count": 471,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ3V-SQV1eTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8028cfa4-8f24-4d20-907b-213ccc643238"
      },
      "source": [
        "string.punctuation = string.punctuation.replace('.', '')\r\n",
        "string.punctuation = string.punctuation.replace(',', '')\r\n",
        "print(string.punctuation)\r\n",
        "data = \"\"\r\n",
        "count=0\r\n",
        "for doc in fileMatrix:\r\n",
        "  # print(doc[0:20])\r\n",
        "  \r\n",
        "  data += \"\".join([char for char in doc if char not in string.punctuation])\r\n",
        "  # print(data[-8:-1])\r\n",
        "  # print(\"\\n\")\r\n",
        "  count +=1\r\n",
        "data = data.replace(\"\\n\", \" \")\r\n",
        "print(count)"
      ],
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+-/:;<=>?@[\\]^_`{|}~\n",
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YR_pMB112Ps_",
        "outputId": "0f808684-ecda-4e4a-aa74-03455b345ebb"
      },
      "source": [
        "data = data.lower()\r\n",
        "data[20:20]"
      ],
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gImA3tAmWEXl"
      },
      "source": [
        ""
      ],
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE_8883pv2-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5b7be5-f128-415d-84db-3d39e8084f68"
      },
      "source": [
        "sents = nltk.sent_tokenize(data)\r\n",
        "print(\"Sentences Count\", len(sents)) \r\n",
        "words = nltk.word_tokenize(data)\r\n",
        "print(\"Tokens Count\", len(words)) \r\n",
        "uq_words = set(words)\r\n",
        "print(\"Unique Words Count\", len(uq_words))"
      ],
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences Count 61495\n",
            "Tokens Count 1117742\n",
            "Unique Words Count 29965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WCA0dzqyKQi"
      },
      "source": [
        "corpus=[]\r\n",
        "for sentence in sents:\r\n",
        "  s = []\r\n",
        "  wr = nltk.word_tokenize(sentence)\r\n",
        "  for w in wr:\r\n",
        "    s.append(w)\r\n",
        "  corpus.append(s)\r\n"
      ],
      "execution_count": 475,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrCJAgR_SJSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b39ef3-2b0e-4ba6-f987-3eee7cf92b88"
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 476,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 476
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-kNXdP35qCS"
      },
      "source": [
        "#Training Trigram models\r\n",
        "# Create a placeholder for model\r\n",
        "model_tri = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "\r\n",
        "# Count frequency of co-occurence  \r\n",
        "for sentence in corpus:\r\n",
        "    # print(sentence)\r\n",
        "    # break;\r\n",
        "    # list(nltk.ngrams(sent, 2))\r\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model_tri[(w1, w2)][w3] += 1\r\n",
        " \r\n",
        "# Let's transform the counts to probabilities\r\n",
        "for w1_w2 in model_tri:\r\n",
        "    total_count = float(sum(model_tri[w1_w2].values()))\r\n",
        "    for w3 in model_tri[w1_w2]:\r\n",
        "        model_tri[w1_w2][w3] /= total_count"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb8wUec2ajdM",
        "outputId": "99a76639-0db2-4cb5-f8cd-88fff536ca80"
      },
      "source": [
        "\r\n",
        "dict(model_tri[\"the\",\"court\"])"
      ],
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': 0.16346153846153846,\n",
              " '.': 0.22115384615384615,\n",
              " 'a': 0.009615384615384616,\n",
              " 'admired': 0.009615384615384616,\n",
              " 'and': 0.0673076923076923,\n",
              " 'are': 0.009615384615384616,\n",
              " 'at': 0.009615384615384616,\n",
              " 'awards': 0.019230769230769232,\n",
              " 'ay': 0.009615384615384616,\n",
              " 'but': 0.009615384615384616,\n",
              " 'can': 0.009615384615384616,\n",
              " 'clean': 0.009615384615384616,\n",
              " 'cupboard': 0.009615384615384616,\n",
              " 'fool': 0.009615384615384616,\n",
              " 'for': 0.009615384615384616,\n",
              " 'gate': 0.019230769230769232,\n",
              " 'here': 0.009615384615384616,\n",
              " 'how': 0.009615384615384616,\n",
              " 'hurry': 0.009615384615384616,\n",
              " 'ill': 0.009615384615384616,\n",
              " 'in': 0.028846153846153848,\n",
              " 'is': 0.009615384615384616,\n",
              " 'lay': 0.009615384615384616,\n",
              " 'let': 0.009615384615384616,\n",
              " 'may': 0.009615384615384616,\n",
              " 'myself': 0.009615384615384616,\n",
              " 'of': 0.1346153846153846,\n",
              " 'portia': 0.009615384615384616,\n",
              " 'receives': 0.009615384615384616,\n",
              " 'shall': 0.009615384615384616,\n",
              " 'sound': 0.009615384615384616,\n",
              " 'third': 0.009615384615384616,\n",
              " 'to': 0.028846153846153848,\n",
              " 'where': 0.009615384615384616,\n",
              " 'why': 0.009615384615384616,\n",
              " 'with': 0.04807692307692308,\n",
              " 'word': 0.009615384615384616}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 478
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py8SAdt226RB",
        "outputId": "dcb321d1-5382-4aa2-b19e-8b735cfd5df3"
      },
      "source": [
        "dict(model_tri[\"skillful\",\"enough\"])"
      ],
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'to': 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 479
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7-pFE8wIrXZ"
      },
      "source": [
        "#Training Bigram models\r\n",
        "# Create a placeholder for model\r\n",
        "model_bi = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "\r\n",
        "# Count frequency of co-occurence  \r\n",
        "for sentence in corpus:\r\n",
        "    # print(sentence)\r\n",
        "    # break;\r\n",
        "    # list(nltk.ngrams(sent, 2))\r\n",
        "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model_bi[w1][w2] += 1\r\n",
        " \r\n",
        "# Let's transform the counts to probabilities\r\n",
        "for w1 in model_bi:\r\n",
        "    total_count = float(sum(model_bi[w1].values()))\r\n",
        "    for w2 in model_bi[w1]:\r\n",
        "        model_bi[w1][w2] /= total_count"
      ],
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sor-US4HIq_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6360ba1b-f2ae-4e02-d523-b032468edc16"
      },
      "source": [
        "dict(model_bi[\"skillful\"])"
      ],
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': 0.2857142857142857,\n",
              " 'conserved': 0.14285714285714285,\n",
              " 'enough': 0.14285714285714285,\n",
              " 'painting': 0.14285714285714285,\n",
              " 'pilots': 0.14285714285714285,\n",
              " 'shepherd': 0.14285714285714285}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRI8QmENpJ5p"
      },
      "source": [
        "**4.** Write a function that takes the following three parameters: model, list of start words,\r\n",
        "number of sentences to generate. This function should return the sentences generated\r\n",
        "as a list. DO NOT print anything to the screen from within the function. Use this function\r\n",
        "to generate 10 sentences with the bigram model from the previous question, and 5\r\n",
        "sentences with the trigram model from the previous question. (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SbtRTPlKHrX"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "def sent_generator(model,textt,n):\r\n",
        "# starting words\r\n",
        "# text = [\"today\", \"the\"]\r\n",
        "  text = textt.copy()\r\n",
        "  final_text=[]\r\n",
        "  for i in range(n):\r\n",
        "    sentence_finished = False\r\n",
        "    complete_text = \"\"\r\n",
        "    while not sentence_finished:\r\n",
        "      # select a random probability threshold  \r\n",
        "      r = random.random()\r\n",
        "      accumulator = .0\r\n",
        "      if(len(text)>1 and len(list(model[tuple(text[-2:])].keys()))>0):\r\n",
        "        # if(len(list(model[tuple(text[-2:])].keys()))>0):\r\n",
        "          for word in model[tuple(text[-2:])].keys():\r\n",
        "\r\n",
        "              accumulator += model[tuple(text[-2:])][word]\r\n",
        "              # select words that are above the probability threshold\r\n",
        "              if accumulator >= r:\r\n",
        "                  text.append(word)\r\n",
        "                  break\r\n",
        "          if text[-2:] == [None, None]:\r\n",
        "              # print(text[-2:])\r\n",
        "              sentence_finished = True\r\n",
        "      elif(len(text)>0 and len(list(model[text[-1]].keys()))>0):\r\n",
        "          for word in model[text[-1]].keys():\r\n",
        "\r\n",
        "              accumulator += model[text[-1]][word]\r\n",
        "              # select words that are above the probability threshold\r\n",
        "              if accumulator >= r:\r\n",
        "                  text.append(word)\r\n",
        "                  break\r\n",
        "\r\n",
        "          if text[-1] == None:\r\n",
        "              sentence_finished = True\r\n",
        "      elif(len(text)>0 and len(list(model[text[-1]].keys()))==0 and len(list(model[tuple(text[-2:])].keys()))==0):\r\n",
        "        sentence_finished = True\r\n",
        "      elif(len(text)==0):\r\n",
        "        text = [\"Invalid text length for start words\"]\r\n",
        "        sentence_finished = True\r\n",
        "\r\n",
        "    complete_text = ' '.join([t for t in text if t])\r\n",
        "\r\n",
        "    final_text.append(complete_text)\r\n",
        "    text = textt.copy()\r\n",
        "  return final_text"
      ],
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ebp7m--Nooq",
        "outputId": "30a64f96-3e82-4cfa-8496-9c1b7c9038ec"
      },
      "source": [
        "output = sent_generator(model_bi,['are','you','lost'],10)\r\n",
        "print(output)\r\n",
        "print(len(output))\r\n",
        "output = sent_generator(model_tri,['are','you','lost'],5)\r\n",
        "print(output)\r\n",
        "print(len(output))"
      ],
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['are you lost .', 'are you lost best pound a boy , above .', 'are you lost and dissolutely .', 'are you lost their reasons are they him for buckingham ay , this twofold marriagetwixt my long .', 'are you lost the hated thee , this charge .', 'are you lost , descended into a creature , rather blamed shall acquittance seal with foul mouth .', 'are you lost .', 'are you lost cousins , that now reign as i am thankful that you mean obsequies that with a means the lady grey and low and here to the net nor the world but ill attach the death can be flattered no more comingon disposition , he done in transformation , in that i fear of my consent .', 'are you lost in your excellent motion turn his but the worthies costard i pray hortensio , sir , that father was troubled with a first friend , tis true delight to the land indeed , with my bedfellow .', 'are you lost when i mean piratesand then , goodman puff of either presuming them .']\n",
            "10\n",
            "['are you lost a dearer father in my life , that have their throats .', 'are you lost a king that took king henrys faithful and honorable personages than the pestilence , and cabin in a saltwaved ocean quench their light and portable my pain , being passed for consul .', 'are you lost your office , as morgan , to read the perfect ways of glory , but one , thou hast made me offer of their lives might breed the silk , any thread , charm ache with air and promise like brabbler the hound , hog .', 'are you lost your son did get your apparel , etc .', 'are you lost by nature .']\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzI7YX5TeMUE",
        "outputId": "4293440f-4022-4b6f-c0ab-34d2d5acf0be"
      },
      "source": [
        "len(list(model_bi['thy'].keys()))"
      ],
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1645"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 484
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esuak1UhgTwA",
        "outputId": "26ba4259-e3c8-4efa-ead4-23fdd53fdd54"
      },
      "source": [
        "model_bi['am'].keys()"
      ],
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['sure', '.', 'going', 'entreating', 'i', 'the', 'none', 'not', 'given', 'delivered', 'your', 'sufficient', 'wondrous', 'as', 'ready', 'resolved', 'happy', 'base', 'proud', 'desperate', 'then', 'in', 'persuaded', 'a', 'moped', 'glad', 'gladder', 'very', 'spared', 'friends', 'well', 'an', 'indifferent', 'i.', 'perfect', 'palamon', 'and', 'set', 'deaf', 'nothing', 'sotted', 'to', ',', 'humbled', 'bridehabited', 'guiltless', 'of', 'much', 'content', 'extinct', 'like', 'most', 'now', 'cruel', 'constant.titus', 'bound', 'weary', 'his', 'attended', 'known', 'light', 'half', 'out', 'so', 'lacked', 'forth', 'joyful', 'longer', 'prepared', 'one', 'bigger', 'hushed', 'here', 'returned', 'struck', 'whipped', 'stung', 'joined', 'accursed', 'bewitched', 'ahorseback', 'sworn', 'no', 'king', 'eight', 'afraid', 'schooled', 'too', 'ignorance', 'doubtless', 'charged', 'withered', 'pacified', 'good', 'heinously', 'on', 'truly', 'thy', 'dubbed', 'sick', 'perplexed', 'with', 'burned', 'almost', 'best', 'hot', 'stifled', 'amazed', 'sent', 'faint', 'scalded', 'brazed', 'made', 'alone', 'richer', 'firm', 'sorry', 'some', 'rough', 'thinking', 'qualified', 'better', 'fool', 'ignorant', 'ashamed', 'scarce', 'bethought', 'fallen', 'old', 'provided', 'cold', 'ill', 'tied', 'slain', 'at', 'worse', 'wretched', 'even', 'cut', 'pregnant', 'only', 'mightily', 'doubtful', 'mainly', 'cast', 'come', 'coming', 'boy', 'afeard', 'welsh', 'qualmish', 'yours', 'thine', 'left', 'by', 'dead', 'nor', 'but', 'braved', 'from', 'marching', 'vanquished', 'prevented', 'able', 'louted', 'unworthy', 'descended', 'possessed', 'assured', 'beloved', 'thought', 'for', 'slow', 'that', 'invisible', 'gone', 'feared', 'marvels', 'such', 'aweary', 'son', 'want', 'clothed', 'unprovided', 'beholding', 'pretty', 'marina', 'great', 'mocked', 'pericles', 'wild', 'stiff', 'dull', 'invited', 'undisposed', 'beaten', 'transformed', 'thee', 'due', 'arrested', 'pressed', 'rested', 'warm', 'waked', 'witness', 'advised', 'dromio', 'worth', 'affined', 'found', 'hitherto', 'changed', 'about', 'evened', 'unfortunate', 'drunk', 'hurt', 'obedient', 'vicious', 'black', 'declined', 'abused', 'entered', 'arraigning', 'commanded', 'deceived', 'maimed', 'othello', 'spoiled', 'yet', 'freely', 'sir', 'damned', 'fain', 'blessed', 'undone', 'undone.fly', 'dejected', 'cozened', 'bereft', 'weaker', 'mad', 'he', 'patroclus', 'agamemnon', 'giddy', 'become', 'above', 'hence', 'achilles', 'thwarted', 'all', 'today', 'offended', 'her', 'bastard', 'unarmed', 'prest', 'debating', 'sandblind', 'lancelet', 'famished', 'bid', 'right', 'contained', 'enjoined', 'forsworn', 'locked', 'armed', 'informed', 'falln', 'married', 'satisfied', 'never', 'th', 'dumb', 'absent', 'any', 'troubled', 'loath', 'thrust', 'exceeding', 'meat', 'robert', 'unwilling', 'passing', 'sleeping', 'fortunes', 'poor', 'driven', 'cressids', 'there', 'past', 'fled', 'run', 'father', 'saint', 'buried', 'heartily', 'returning', 'shall', 'supposed', 'wrapped', 'either', 'debarred', 'sufficed', 'sometime', 'still', 'shamed', 'rotten', 'attainted', 'confined', 'forsaken', 'mortgaged', 'near', 'blind', 'perjured', 'egypts', 'full', 'dancing', 'sudden', 'quickly', 'certain', 'pale', 'paid', 'prompt', 'antony', 'onioneyed', 'revenged', 'conqueror', 'dying', 'safe', 'called', 'again', 'marbleconstant', 'fire', 'questioned', 'angling', 'galledmightst', 'appointed', 'innocent', 'accused', 'barred', 'ere', 'robbed', 'false', 'heir', 'put', 'therefore', 'courtier', 'courted', 'proof', 'friend', 'assisted', 'lost', 'sound', 'customshrunk', 'committed', 'drawn', 'confessor', 'always', 'sleepy', 'directed', 'combined', 'touched', 'affianced', 'more', 'confident', 'incorporate', 'graced', 'surprised', 'revenge', 'barren', 'willing', 'man', 'woman', 'true', 'dog', 'indeed', 'master', 'shent', 'viola', 'pleased', 'bold', 'protector', 'unmeet', 'falsely', 'duke', 'loyal', 'clear', 'faulty', 'ruler', 'banished', 'smith', 'rightful', 'far', 'peremptory', 'drowned', 'nourished', 'myself', 'dearer', 'impatient', 'crossed', 'betrothed', 'thus', 'my', 'proteus', 'thane', 'fed', 'settled', 'reckless', 'cabined', 'bent', 'young', 'loved', 'claudio', 'drowsy', 'merry', 'trusted', 'subdued', 'heartburned', 'apt', 'sunburnt', 'censured', 'stuffed', 'engaged', 'forced', 'senseless', 'something', 'sprighted', 'last', 'morgan', 'stale', 'soldier', 'throughly', 'weak', 'absolute', 'honest', 'brought', 'awake', 'merrier', 'posthumus', 'sorrow', 'truest', 'down', 'naples', 'standing', 'trinculobe', 'skilless', 'subject', 'vexed', 'woe', 'prospero', 'hers', 'christophero', 'arrived', 'agreed', 'tranio', 'grumios', 'moved', 'born', 'lucentio', 'forbid', 'dogweary', 'starved', 'mean', 'native', 'two', 'pigeonlivered', 'tame', 'easier', 'let', 'constant', 'punished', 'justly', 'poisoned', 'helping', 'before', 'altogether', 'mistress', 'notthen', 'strong', 'shepherd', 'ambitious', 'wise', 'caparisoned', 'foul', 'falser', 'remembered', 'neither', 'wealthy', 'een', 'misanthropos', 'unlearned', 'quit', 'rapt', 'disgraced', 'denied', 'greater', 'unkinged', 'rudely', 'curtailed', 'determined', 'subtle', 'misshapen', 'crept', 'stern', 'she', 'queen', 'strongframed', 'little', 'stanley', 'unfit', 'their', 'hungry', 'proverbed', 'done', 'sped', 'peppered', 'sold', 'ever', 'laid', 'thence', 'edward', 'caesar', 'promised', 'meek', 'cinna', 'fresh', 'free', 'brutus', 'anthony', 'answered', 'less', 'fair', 'thankful', 'coursing', 'toiling', 'betrayed', 'compared', 'stabbed', 'berowne', 'boyet', 'alisander', 'dumaine', 'solicited', 'boldened', 'traduced', 'wife', 'forgotten', 'happily', 'fearful'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 485
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shNE5nVVXjzK",
        "outputId": "d1d3b73b-c7aa-4175-d300-3f2b618af2f8"
      },
      "source": [
        "if(model_tri[tuple(['i','am'])].keys()!=[]):\r\n",
        "  print(\"jj\")"
      ],
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrXmRDfQAB-E"
      },
      "source": [
        "**Bonus** (20 points): Using the same methodology from questions 1 and 2, create a\r\n",
        "similarity matrix between the 20 newsgroups corpus. And find the top 5 similar\r\n",
        "newsgroups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnWCpe_xAHJN",
        "outputId": "9877e4ed-af62-43f0-8b13-cfdd5aa6851b"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\r\n",
        "\r\n",
        "data = fetch_20newsgroups()\r\n",
        "data.target_names"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dXauEEgPWbxA",
        "outputId": "c1118eb0-7262-4f5b-c8e0-534a2aa9dcba"
      },
      "source": [
        "data.target_names[1]\r\n",
        "# for i in data.target_names:\r\n",
        "#   print(i)"
      ],
      "execution_count": 488,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'comp.graphics'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB74Qi5TT6mv"
      },
      "source": [
        "final_data = []\r\n",
        "text_data = \"\"\r\n",
        "for i in data.target_names:\r\n",
        "  train = fetch_20newsgroups(subset='train', categories=[i])\r\n",
        "  # test = fetch_20newsgroups(subset='test', categories=categories)\r\n",
        "  for j in train.data:\r\n",
        "    text_data += \" \"+j\r\n",
        "  final_data.append(text_data)\r\n"
      ],
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1bFVqPIUWtJ",
        "outputId": "086d1afd-4d12-4e03-d7df-9762c73115ea"
      },
      "source": [
        "len(final_data)"
      ],
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 490
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8yjObbpTboW"
      },
      "source": [
        ""
      ],
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW3GIPAjTm58",
        "outputId": "f82ebd73-a874-4a29-a085-c5b05be50410"
      },
      "source": [
        "#TfidfVectorizer object\r\n",
        "vectorizer = TfidfVectorizer()\r\n",
        "\r\n",
        "# matrix of word vectors\r\n",
        "tfidf_matrix = vectorizer.fit_transform(final_data)\r\n",
        "\r\n",
        "#shape of tfidf_matrix\r\n",
        "print(tfidf_matrix.shape)"
      ],
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 130107)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvyf35Y2Tt1i",
        "outputId": "7fda18a3-8460-4e8c-dbc9-4af00c30c056"
      },
      "source": [
        "tfidf_tokens = vectorizer.get_feature_names()\r\n",
        "print(tfidf_tokens[10000:10005])\r\n",
        "print(len(tfidf_tokens))"
      ],
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['26m', '26n', '26q', '26ql24do2', '26qz_l']\n",
            "130107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdGB0j6ITxPQ"
      },
      "source": [
        "# compute and print the cosine similarity matrix\r\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
      ],
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmLF1CloTz35",
        "outputId": "616523b5-564d-4293-ddb1-a4e3dc8b226a"
      },
      "source": [
        "print(cosine_sim.shape)\r\n",
        "print(cosine_sim)"
      ],
      "execution_count": 494,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 20)\n",
            "[[1.         0.99014536 0.38420893 0.46601216 0.53228932 0.62105783\n",
            "  0.64370599 0.69568878 0.73208498 0.76417605 0.79571894 0.83594542\n",
            "  0.8504816  0.86976691 0.88353065 0.90408429 0.91499735 0.92675252\n",
            "  0.93401827 0.93858153]\n",
            " [0.99014536 1.         0.3900986  0.47448653 0.54268787 0.6342324\n",
            "  0.65882102 0.71116798 0.74805383 0.78006296 0.81171952 0.85180951\n",
            "  0.86670461 0.88565865 0.89964864 0.91797864 0.92823376 0.93895093\n",
            "  0.94545396 0.94935981]\n",
            " [0.38420893 0.3900986  1.         0.99499454 0.98333801 0.95549826\n",
            "  0.94469761 0.91811517 0.89426445 0.8698225  0.83920372 0.79662421\n",
            "  0.7774654  0.75286838 0.72984299 0.70087402 0.67936352 0.65085721\n",
            "  0.63362786 0.62368582]\n",
            " [0.46601216 0.47448653 0.99499454 1.         0.99645716 0.97963774\n",
            "  0.97210509 0.95229565 0.93347091 0.91345498 0.88760046 0.85097773\n",
            "  0.83430203 0.81256299 0.79196804 0.76575067 0.74615537 0.7198376\n",
            "  0.7039312  0.69471071]\n",
            " [0.53228932 0.54268787 0.98333801 0.99645716 1.         0.99266725\n",
            "  0.98794102 0.9740683  0.95967009 0.9436547  0.9221443  0.89086661\n",
            "  0.87643456 0.85728852 0.83895757 0.81530393 0.79751554 0.77332513\n",
            "  0.75868226 0.75015008]\n",
            " [0.62105783 0.6342324  0.95549826 0.97963774 0.99266725 1.\n",
            "  0.99910034 0.99366517 0.98563492 0.97531917 0.96014671 0.93718904\n",
            "  0.92609507 0.91091544 0.89609    0.87647487 0.8615116  0.84070298\n",
            "  0.828064   0.82063277]\n",
            " [0.64370599 0.65882102 0.94469761 0.97210509 0.98794102 0.99910034\n",
            "  1.         0.99702702 0.99088284 0.98228451 0.9689263  0.94812793\n",
            "  0.93803148 0.9240499  0.91021951 0.89161091 0.87740717 0.85743596\n",
            "  0.84530705 0.83816889]\n",
            " [0.69568878 0.71116798 0.91811517 0.95229565 0.9740683  0.99366517\n",
            "  0.99702702 1.         0.99822292 0.99357577 0.98457065 0.96908986\n",
            "  0.96122087 0.9499491  0.9384886  0.92271076 0.91054293 0.89308592\n",
            "  0.88242251 0.87609491]\n",
            " [0.73208498 0.74805383 0.89426445 0.93347091 0.95967009 0.98563492\n",
            "  0.99088284 0.99822292 1.         0.99835683 0.99268943 0.9812798\n",
            "  0.97513189 0.96596369 0.95634579 0.9427354  0.93214538 0.91664673\n",
            "  0.90712861 0.90143571]\n",
            " [0.76417605 0.78006296 0.8698225  0.91345498 0.9436547  0.97531917\n",
            "  0.98228451 0.99357577 0.99835683 1.         0.99776941 0.99011181\n",
            "  0.98551584 0.97831396 0.97045489 0.95898673 0.94989502 0.93632435\n",
            "  0.92789648 0.92281507]\n",
            " [0.79571894 0.81171952 0.83920372 0.88760046 0.9221443  0.96014671\n",
            "  0.9689263  0.98457065 0.99268943 0.99776941 1.         0.99660719\n",
            "  0.99374844 0.98864738 0.98282789 0.97372623 0.96635389 0.9550996\n",
            "  0.94791556 0.94350934]\n",
            " [0.83594542 0.85180951 0.79662421 0.85097773 0.89086661 0.93718904\n",
            "  0.94812793 0.96908986 0.9812798  0.99011181 0.99660719 1.\n",
            "  0.99946306 0.99733069 0.99415243 0.98835172 0.98326262 0.97488232\n",
            "  0.96940992 0.96595525]\n",
            " [0.8504816  0.86670461 0.7774654  0.83430203 0.87643456 0.92609507\n",
            "  0.93803148 0.96122087 0.97513189 0.98551584 0.99374844 0.99946306\n",
            "  1.         0.99906463 0.99694727 0.99240602 0.98822049 0.98092516\n",
            "  0.97611854 0.97303658]\n",
            " [0.86976691 0.88565865 0.75286838 0.81256299 0.85728852 0.91091544\n",
            "  0.9240499  0.9499491  0.96596369 0.97831396 0.98864738 0.99733069\n",
            "  0.99906463 1.         0.99925245 0.99653084 0.99353161 0.98774869\n",
            "  0.98383231 0.98128778]\n",
            " [0.88353065 0.89964864 0.72984299 0.79196804 0.83895757 0.89609\n",
            "  0.91021951 0.9384886  0.95634579 0.97045489 0.98282789 0.99415243\n",
            "  0.99694727 0.99925245 1.         0.99874988 0.99680932 0.99244656\n",
            "  0.98930962 0.98719806]\n",
            " [0.90408429 0.91797864 0.70087402 0.76575067 0.81530393 0.87647487\n",
            "  0.89161091 0.92271076 0.9427354  0.95898673 0.97372623 0.98835172\n",
            "  0.99240602 0.99653084 0.99874988 1.         0.99943336 0.99692707\n",
            "  0.99488468 0.9934756 ]\n",
            " [0.91499735 0.92823376 0.67936352 0.74615537 0.79751554 0.8615116\n",
            "  0.87740717 0.91054293 0.93214538 0.94989502 0.96635389 0.98326262\n",
            "  0.98822049 0.99353161 0.99680932 0.99943336 1.         0.99881605\n",
            "  0.99752113 0.99652947]\n",
            " [0.92675252 0.93895093 0.65085721 0.7198376  0.77332513 0.84070298\n",
            "  0.85743596 0.89308592 0.91664673 0.93632435 0.9550996  0.97488232\n",
            "  0.98092516 0.98774869 0.99244656 0.99692707 0.99881605 1.\n",
            "  0.99965805 0.99921674]\n",
            " [0.93401827 0.94545396 0.63362786 0.7039312  0.75868226 0.828064\n",
            "  0.84530705 0.88242251 0.90712861 0.92789648 0.94791556 0.96940992\n",
            "  0.97611854 0.98383231 0.98930962 0.99488468 0.99752113 0.99965805\n",
            "  1.         0.99988265]\n",
            " [0.93858153 0.94935981 0.62368582 0.69471071 0.75015008 0.82063277\n",
            "  0.83816889 0.87609491 0.90143571 0.92281507 0.94350934 0.96595525\n",
            "  0.97303658 0.98128778 0.98719806 0.9934756  0.99652947 0.99921674\n",
            "  0.99988265 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmjP9x9nXSli",
        "outputId": "7e18592e-8df3-4063-d5fc-30ba4252120e"
      },
      "source": [
        "def find_similar_docs(matrix,n):\r\n",
        "  docs=[]\r\n",
        "  final_doc=[]\r\n",
        "  np.fill_diagonal(matrix, 0)\r\n",
        "  n=n*2\r\n",
        "  idx = np.argsort(matrix.ravel())[:-n-1:-1]\r\n",
        "  similar = np.column_stack(np.unravel_index(idx, matrix.shape))\r\n",
        "  for i in range(n):\r\n",
        "    docs.append(data.target_names[similar[i][0]])\r\n",
        "  for i in range(0,len(docs)-1,2):\r\n",
        "    final_doc.append(docs[i]+\" && \"+docs[i+1])\r\n",
        "  print(\"The newsgroup pairs are:\")\r\n",
        "  for i in final_doc:\r\n",
        "    print(i)\r\n",
        "find_similar_docs(cosine_sim,5)\r\n",
        "# print(out)\r\n"
      ],
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The newsgroup pairs are:\n",
            "talk.politics.misc && talk.religion.misc\n",
            "talk.politics.misc && talk.politics.mideast\n",
            "sci.crypt && sci.electronics\n",
            "soc.religion.christian && talk.politics.guns\n",
            "sci.space && sci.med\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iC4CeCDZv4I",
        "outputId": "d28f0380-a9ad-4f2d-9e32-014ba48f58bf"
      },
      "source": [
        "def find_similar_docs(matrix,n):\r\n",
        "  docs=[]\r\n",
        "  np.fill_diagonal(matrix, 0)\r\n",
        "  idx = np.argsort(matrix.ravel())[:-n-1:-1]\r\n",
        "  similar = np.column_stack(np.unravel_index(idx, matrix.shape))\r\n",
        "  for i in range(n):\r\n",
        "    docs.append(data.target_names[similar[i][0]])\r\n",
        "  return docs\r\n",
        "out = find_similar_docs(cosine_sim,5)\r\n",
        "print(out)\r\n",
        "print(\"The list is:\")\r\n",
        "for i in out:\r\n",
        "  print(i)"
      ],
      "execution_count": 496,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['talk.politics.misc', 'talk.religion.misc', 'talk.politics.misc', 'talk.politics.mideast', 'sci.crypt']\n",
            "The list is:\n",
            "talk.politics.misc\n",
            "talk.religion.misc\n",
            "talk.politics.misc\n",
            "talk.politics.mideast\n",
            "sci.crypt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}